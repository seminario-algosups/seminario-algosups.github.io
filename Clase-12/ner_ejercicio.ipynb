{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e513747",
   "metadata": {},
   "source": [
    "# Ejercicio práctico — Extracción de Entidades en Noticias en Español\n",
    "\n",
    "Este cuaderno implementa paso a paso el ejercicio que compara dos enfoques de **Named Entity Recognition (NER)**:\n",
    "1. Un sistema *rule‑based* minimalista (regex + gazetteer).\n",
    "2. Un modelo Transformer pre‑entrenado y ajustado para NER en español.\n",
    "\n",
    "**Objetivos de aprendizaje**\n",
    "- Comprender el concepto de *entidad nombrada* y su papel en PLN.\n",
    "- Implementar y evaluar un detector de entidades basado en reglas.\n",
    "- Aplicar un modelo de estado‑del‑arte y comparar resultados.\n",
    "- Analizar errores y reflexionar sobre la idoneidad de cada enfoque."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2875519d",
   "metadata": {},
   "source": [
    "## 1 · Instalación de dependencias\n",
    "Ejecuta la siguiente celda para instalar las bibliotecas necesarias. *(En Colab se tarda < 1 min).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b86b13f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q datasets seqeval fugashi ipadic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08107e83",
   "metadata": {},
   "source": [
    "## 2 · Carga del corpus CoNLL‑2002 (español)\n",
    "Tomaremos una **muestra pequeña** para acelerar los experimentos; puedes aumentar el número de frases si tu entorno lo permite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdb23267",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlos.schiaffino/projects/cursos/seminario-algosups.github.io/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading data: 100%|██████████| 2.97M/2.97M [00:00<00:00, 15.7MB/s]\n",
      "Downloading data: 100%|██████████| 594k/594k [00:00<00:00, 19.4MB/s]\n",
      "Downloading data: 100%|██████████| 576k/576k [00:00<00:00, 18.1MB/s]\n",
      "Generating train split: 100%|██████████| 8324/8324 [00:00<00:00, 22469.90 examples/s]\n",
      "Generating validation split: 100%|██████████| 1916/1916 [00:00<00:00, 25178.31 examples/s]\n",
      "Generating test split: 100%|██████████| 1518/1518 [00:00<00:00, 21158.01 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Melbourne', '(', 'Australia', ')', ',', '25', 'may', '(', 'EFE', ')', '.']\n",
      "[5, 0, 5, 0, 0, 0, 0, 0, 3, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "conll_es = load_dataset('conll2002', 'es')\n",
    "train_ds = conll_es['train'].select(range(2000))   # 2 000 oraciones\n",
    "test_ds  = conll_es['test'].select(range(500))     #   500 oraciones\n",
    "\n",
    "print(train_ds[0]['tokens'])\n",
    "print(train_ds[0]['ner_tags'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c6cf32",
   "metadata": {},
   "source": [
    "## 3 · Enfoque A — Reglas + Gazetteer\n",
    "### 3.1 Crear un **gazetteer** minimalista\n",
    "Añade, modifica o amplía las listas para experimentar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef293882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, random\n",
    "from itertools import chain\n",
    "\n",
    "GAZETTEER_LOC = {\n",
    "    'Madrid', 'Buenos Aires', 'Barcelona', 'Ciudad de México',\n",
    "    'Sevilla', 'Valencia', 'Montevideo', 'Santiago',\n",
    "    'Bogotá', 'Lima', 'Caracas', 'Asunción', 'Quito',\n",
    "}\n",
    "\n",
    "# Regex muy simple para años de cuatro dígitos\n",
    "DATE_RE = re.compile(r'\\b\\d{4}\\b')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa87997",
   "metadata": {},
   "source": [
    "### 3.2 Función de NER basada en reglas\n",
    "Completa `rule_based_ner(tokens)` de modo que devuelva una lista de etiquetas BIO alineada con `tokens`.\n",
    "\n",
    "> **TIP**: Etiquetas válidas en CoNLL‑2002: `B-LOC`, `I-LOC`, `B-PER`, `I-PER`, `B-ORG`, `I-ORG`, `B-MISC`, `I-MISC`, `O`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2f7690e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-LOC', 'O', 'O', 'B-MISC', 'O']\n"
     ]
    }
   ],
   "source": [
    "def rule_based_ner(tokens):\n",
    "    labels = []\n",
    "    for tok in tokens:\n",
    "        if tok in GAZETTEER_LOC:\n",
    "            labels.append('B-LOC')\n",
    "        elif DATE_RE.match(tok):\n",
    "            labels.append('B-MISC')  # usamos MISC para fechas\n",
    "        else:\n",
    "            labels.append('O')\n",
    "    return labels\n",
    "\n",
    "# Ejemplo rápido\n",
    "example = ['Barcelona', 'ganó', 'en', '1992', '.']\n",
    "print(rule_based_ner(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0d5202",
   "metadata": {},
   "source": [
    "### 3.3 Evaluación del sistema de reglas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf2a5838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.45      0.07      0.12       303\n",
      "        MISC       0.00      0.00      0.00       117\n",
      "         ORG       0.00      0.00      0.00       480\n",
      "         PER       0.00      0.00      0.00       231\n",
      "\n",
      "   micro avg       0.27      0.02      0.03      1131\n",
      "   macro avg       0.11      0.02      0.03      1131\n",
      "weighted avg       0.12      0.02      0.03      1131\n",
      "\n",
      "F1 macro: 0.0347682119205298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlos.schiaffino/projects/cursos/seminario-algosups.github.io/.venv/lib/python3.13/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report, f1_score\n",
    "\n",
    "y_true, y_pred = [], []\n",
    "for row in test_ds:\n",
    "    y_true.append([test_ds.features['ner_tags'].feature.names[tag] for tag in row['ner_tags']])\n",
    "    y_pred.append(rule_based_ner(row['tokens']))\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "print('F1 macro:', f1_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857126ed",
   "metadata": {},
   "source": [
    "## 4 · Enfoque B — Modelo Transformer pre‑entrenado\n",
    "Utilizaremos el modelo `mrm8488/bert-spanish-cased-finetuned-ner` disponible en Hugging Face. Puedes cambiarlo por otro para comparar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b89caa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2adf4e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at mrm8488/bert-spanish-cased-finetuned-ner were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "\n",
    "model_ckpt = 'mrm8488/bert-spanish-cased-finetuned-ner'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_ckpt)\n",
    "\n",
    "# Creamos pipeline con agrupación de tokens en spans (simple)\n",
    "ner_pipe = pipeline('token-classification', model=model, tokenizer=tokenizer, aggregation_strategy='simple')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206504b6",
   "metadata": {},
   "source": [
    "### 4.1 Conversión de la salida del pipeline a BIO tags\n",
    "El siguiente helper transforma los spans del pipeline a etiquetas BIO alineadas con los tokens originales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32e8b0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_to_bio(tokens, spans):\n",
    "    labels = ['O'] * len(tokens)\n",
    "    for sp in spans:\n",
    "        ent_tokens = tokenizer.tokenize(sp['word'])  # tokenización aproximada\n",
    "        # buscamos la primera ocurrencia\n",
    "        try:\n",
    "            start_idx = tokens.index(ent_tokens[0])\n",
    "        except ValueError:\n",
    "            continue\n",
    "        labels[start_idx] = f\"B-{sp['entity_group'].upper()}\"\n",
    "        for j in range(1, len(ent_tokens)):\n",
    "            if start_idx + j < len(labels):\n",
    "                labels[start_idx + j] = f\"I-{sp['entity_group'].upper()}\"\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b811e8",
   "metadata": {},
   "source": [
    "### 4.2 Etiquetado del conjunto de prueba y evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cf9a0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.81      0.50      0.62       303\n",
      "        MISC       0.49      0.29      0.37       117\n",
      "         ORG       0.76      0.41      0.53       480\n",
      "         PER       0.45      0.21      0.29       231\n",
      "\n",
      "   micro avg       0.69      0.38      0.49      1131\n",
      "   macro avg       0.63      0.35      0.45      1131\n",
      "weighted avg       0.68      0.38      0.49      1131\n",
      "\n",
      "F1 macro: 0.49232518476407044\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = [], []\n",
    "for row in test_ds:\n",
    "    tokens = row['tokens']\n",
    "    spans = ner_pipe(' '.join(tokens))\n",
    "    y_true.append([test_ds.features['ner_tags'].feature.names[tag] for tag in row['ner_tags']])\n",
    "    y_pred.append(pipeline_to_bio(tokens, spans))\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "print('F1 macro:', f1_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19ed551",
   "metadata": {},
   "source": [
    "## 5 · Comparación y discusión\n",
    "Completa la siguiente tabla (manualmente o con código) copiando las métricas obtenidas.\n",
    "\n",
    "| Sistema | F1 macro | PER | ORG | LOC | MISC |\n",
    "|---------|----------|-----|-----|-----|------|\n",
    "| Reglas  |          |     |     |     |      |\n",
    "| BERT    |          |     |     |     |      |\n",
    "\n",
    "Reflexiona:\n",
    "- ¿En qué tipos de entidad se nota mayor diferencia?\n",
    "- ¿Qué errores comete el sistema de reglas?\n",
    "- ¿Por qué el modelo neuronal podría fallar en ciertos nombres propios poco frecuentes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819ebc65",
   "metadata": {},
   "source": [
    "## 6 · Análisis cualitativo de errores\n",
    "Extrae ejemplos donde el modelo Transformer falló. Clasifica cada error como *boundary*, *mis‑class* o *miss*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f2d66ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>gold</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La Coruña , 23 may ( EFECOM ) .</td>\n",
       "      <td>[B-LOC, I-LOC, O, O, O, O, B-ORG, O, O]</td>\n",
       "      <td>[B-LOC, I-LOC, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Al acto acudieron , además de los accionistas ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fuera de ambas alianzas dentro de la CEI , eco...</td>\n",
       "      <td>[O, O, O, O, O, O, O, B-ORG, O, O, O, O, O, O,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Madrid , 23 may ( EFE ) .</td>\n",
       "      <td>[B-LOC, O, O, O, O, B-ORG, O, O]</td>\n",
       "      <td>[B-LOC, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Por su parte , el secretario provincial del PS...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, B-ORG, I-ORG, I-ORG, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, B-ORG, I-ORG, I-ORG, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Según la información facilitada hoy por la Jef...</td>\n",
       "      <td>[O, O, O, O, O, O, O, B-ORG, I-ORG, I-ORG, I-O...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Otro ausente será el defensa Ned Zelic ( 1860 ...</td>\n",
       "      <td>[O, O, O, O, O, B-PER, I-PER, O, O, B-LOC, O, ...</td>\n",
       "      <td>[O, O, O, O, O, B-PER, I-PER, O, O, O, O, B-LO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>El presidente de Aceralia , José Ramón Alvarez...</td>\n",
       "      <td>[O, O, O, B-ORG, O, B-PER, I-PER, I-PER, I-PER...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Una treintena de asociaciones que integran la ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-PER, I-PER...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-PER, I-PER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rusia , a su vez , rechaza la intención de sus...</td>\n",
       "      <td>[B-ORG, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "      <td>[B-ORG, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>El presidente ruso , Vladímir Putin , abordó e...</td>\n",
       "      <td>[O, O, O, O, B-PER, I-PER, O, O, O, O, O, O, O...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Toledo , 23 may ( EFE ) .</td>\n",
       "      <td>[B-LOC, O, O, O, O, B-ORG, O, O]</td>\n",
       "      <td>[B-LOC, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>La delegada en Cádiz de la Consejería de Asunt...</td>\n",
       "      <td>[O, O, O, B-LOC, O, O, B-ORG, I-ORG, I-ORG, I-...</td>\n",
       "      <td>[O, O, O, B-LOC, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Destacó que la Politécnica ha alcanzado la ple...</td>\n",
       "      <td>[O, O, O, B-ORG, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>El claustro extraordinario de la Universidad d...</td>\n",
       "      <td>[O, O, O, O, O, B-ORG, I-ORG, I-ORG, O, B-ORG,...</td>\n",
       "      <td>[O, O, O, O, O, B-ORG, I-ORG, I-ORG, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Para UGT de Madrid , la decisión de la UE alej...</td>\n",
       "      <td>[O, B-ORG, O, B-LOC, O, O, O, O, O, B-ORG, O, ...</td>\n",
       "      <td>[O, O, O, B-LOC, O, O, O, O, O, B-ORG, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A las 16.00 . e , en el Hotel Ciudad de Logroñ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, B-LOC, I-LOC, I-LOC, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, B-LOC, I-LOC, I-LOC, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>El diplomático ghaneano se refería así a la es...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Moneo confió en que antes de final de año pued...</td>\n",
       "      <td>[B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Luis Mendoza , directivo de la Federación Rioj...</td>\n",
       "      <td>[B-PER, I-PER, O, O, O, O, B-ORG, I-ORG, I-ORG...</td>\n",
       "      <td>[B-PER, I-PER, O, O, O, O, B-ORG, I-ORG, I-ORG...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "0                     La Coruña , 23 may ( EFECOM ) .   \n",
       "1   Al acto acudieron , además de los accionistas ...   \n",
       "2   Fuera de ambas alianzas dentro de la CEI , eco...   \n",
       "3                           Madrid , 23 may ( EFE ) .   \n",
       "4   Por su parte , el secretario provincial del PS...   \n",
       "5   Según la información facilitada hoy por la Jef...   \n",
       "6   Otro ausente será el defensa Ned Zelic ( 1860 ...   \n",
       "7   El presidente de Aceralia , José Ramón Alvarez...   \n",
       "8   Una treintena de asociaciones que integran la ...   \n",
       "9   Rusia , a su vez , rechaza la intención de sus...   \n",
       "10  El presidente ruso , Vladímir Putin , abordó e...   \n",
       "11                          Toledo , 23 may ( EFE ) .   \n",
       "12  La delegada en Cádiz de la Consejería de Asunt...   \n",
       "13  Destacó que la Politécnica ha alcanzado la ple...   \n",
       "14  El claustro extraordinario de la Universidad d...   \n",
       "15  Para UGT de Madrid , la decisión de la UE alej...   \n",
       "16  A las 16.00 . e , en el Hotel Ciudad de Logroñ...   \n",
       "17  El diplomático ghaneano se refería así a la es...   \n",
       "18  Moneo confió en que antes de final de año pued...   \n",
       "19  Luis Mendoza , directivo de la Federación Rioj...   \n",
       "\n",
       "                                                 gold  \\\n",
       "0             [B-LOC, I-LOC, O, O, O, O, B-ORG, O, O]   \n",
       "1   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "2   [O, O, O, O, O, O, O, B-ORG, O, O, O, O, O, O,...   \n",
       "3                    [B-LOC, O, O, O, O, B-ORG, O, O]   \n",
       "4   [O, O, O, O, O, O, O, O, B-ORG, I-ORG, I-ORG, ...   \n",
       "5   [O, O, O, O, O, O, O, B-ORG, I-ORG, I-ORG, I-O...   \n",
       "6   [O, O, O, O, O, B-PER, I-PER, O, O, B-LOC, O, ...   \n",
       "7   [O, O, O, B-ORG, O, B-PER, I-PER, I-PER, I-PER...   \n",
       "8   [O, O, O, O, O, O, O, O, O, O, O, B-PER, I-PER...   \n",
       "9   [B-ORG, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
       "10  [O, O, O, O, B-PER, I-PER, O, O, O, O, O, O, O...   \n",
       "11                   [B-LOC, O, O, O, O, B-ORG, O, O]   \n",
       "12  [O, O, O, B-LOC, O, O, B-ORG, I-ORG, I-ORG, I-...   \n",
       "13  [O, O, O, B-ORG, O, O, O, O, O, O, O, O, O, O,...   \n",
       "14  [O, O, O, O, O, B-ORG, I-ORG, I-ORG, O, B-ORG,...   \n",
       "15  [O, B-ORG, O, B-LOC, O, O, O, O, O, B-ORG, O, ...   \n",
       "16  [O, O, O, O, O, O, O, O, B-LOC, I-LOC, I-LOC, ...   \n",
       "17  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "18  [B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
       "19  [B-PER, I-PER, O, O, O, O, B-ORG, I-ORG, I-ORG...   \n",
       "\n",
       "                                                 pred  \n",
       "0                 [B-LOC, I-LOC, O, O, O, O, O, O, O]  \n",
       "1   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "2   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3                        [B-LOC, O, O, O, O, O, O, O]  \n",
       "4   [O, O, O, O, O, O, O, O, B-ORG, I-ORG, I-ORG, ...  \n",
       "5   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "6   [O, O, O, O, O, B-PER, I-PER, O, O, O, O, B-LO...  \n",
       "7   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "8   [O, O, O, O, O, O, O, O, O, O, O, B-PER, I-PER...  \n",
       "9   [B-ORG, O, O, O, O, O, O, O, O, O, O, O, O, O,...  \n",
       "10  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "11                       [B-LOC, O, O, O, O, O, O, O]  \n",
       "12  [O, O, O, B-LOC, O, O, O, O, O, O, O, O, O, O,...  \n",
       "13  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "14  [O, O, O, O, O, B-ORG, I-ORG, I-ORG, O, O, O, ...  \n",
       "15  [O, O, O, B-LOC, O, O, O, O, O, B-ORG, O, O, O...  \n",
       "16  [O, O, O, O, O, O, O, O, B-LOC, I-LOC, I-LOC, ...  \n",
       "17  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "18  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "19  [B-PER, I-PER, O, O, O, O, B-ORG, I-ORG, I-ORG...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random, pandas as pd\n",
    "\n",
    "error_samples = []\n",
    "for row, pred in zip(test_ds, y_pred):\n",
    "    gold = [test_ds.features['ner_tags'].feature.names[tag] for tag in row['ner_tags']]\n",
    "    if gold != pred:\n",
    "        error_samples.append({'text': ' '.join(row['tokens']), 'gold': gold, 'pred': pred})\n",
    "\n",
    "sampled = random.sample(error_samples, 20)\n",
    "pd.DataFrame(sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8ed347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Oro (gold):\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'display' from 'IPython.core.display' (/Users/carlos.schiaffino/projects/cursos/seminario-algosups.github.io/.venv/lib/python3.13/site-packages/IPython/core/display.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     31\u001b[39m pred_labels = y_pred[idx]\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m🔹 Oro (gold):\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[43mdisplacy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbio_to_spacy_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgold_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43ment\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjupyter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m🔸 Predicción BERT:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     37\u001b[39m displacy.render(bio_to_spacy_doc(tokens, pred_labels), style=\u001b[33m\"\u001b[39m\u001b[33ment\u001b[39m\u001b[33m\"\u001b[39m, jupyter=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/cursos/seminario-algosups.github.io/.venv/lib/python3.13/site-packages/spacy/displacy/__init__.py:69\u001b[39m, in \u001b[36mrender\u001b[39m\u001b[34m(docs, style, page, minify, jupyter, options, manual)\u001b[39m\n\u001b[32m     65\u001b[39m     html = RENDER_WRAPPER(html)\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m jupyter \u001b[38;5;129;01mor\u001b[39;00m (jupyter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_in_jupyter()):\n\u001b[32m     67\u001b[39m     \u001b[38;5;66;03m# return HTML rendered by IPython display()\u001b[39;00m\n\u001b[32m     68\u001b[39m     \u001b[38;5;66;03m# See #4840 for details on span wrapper to disable mathjax\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HTML, display\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m display(HTML(\u001b[33m'\u001b[39m\u001b[33m<span class=\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtex2jax_ignore\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m>\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m</span>\u001b[39m\u001b[33m'\u001b[39m.format(html)))\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m html\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'display' from 'IPython.core.display' (/Users/carlos.schiaffino/projects/cursos/seminario-algosups.github.io/.venv/lib/python3.13/site-packages/IPython/core/display.py)"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.tokens import Doc, Span\n",
    "from spacy import displacy\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Crea un nlp vacío solo para construir Doc/Span\n",
    "nlp_blank = spacy.blank(\"es\")\n",
    "\n",
    "def bio_to_spacy_doc(tokens, labels):\n",
    "    \"\"\"Convierte tokens + BIO en un Doc con entidades SpaCy.\"\"\"\n",
    "    doc = Doc(nlp_blank.vocab, words=tokens)\n",
    "    spans = []\n",
    "    i = 0\n",
    "    while i < len(labels):\n",
    "        if labels[i].startswith(\"B-\"):\n",
    "            ent_type = labels[i][2:]\n",
    "            start = i\n",
    "            i += 1\n",
    "            while i < len(labels) and labels[i].startswith(\"I-\"):\n",
    "                i += 1\n",
    "            spans.append(Span(doc, start, i, label=ent_type))\n",
    "        else:\n",
    "            i += 1\n",
    "    doc.ents = spans\n",
    "    return doc\n",
    "\n",
    "# ─── muestra aleatoria ────────────────────────────────────────────\n",
    "idx = random.randint(0, len(test_ds) - 1)\n",
    "tokens = test_ds[idx][\"tokens\"]\n",
    "gold_labels = [test_ds.features[\"ner_tags\"].feature.names[t] for t in test_ds[idx][\"ner_tags\"]]\n",
    "pred_labels = y_pred[idx]\n",
    "\n",
    "print(\"🔹 Oro (gold):\")\n",
    "displacy.render(bio_to_spacy_doc(tokens, gold_labels), style=\"ent\", jupyter=True)\n",
    "\n",
    "print(\"🔸 Predicción BERT:\")\n",
    "displacy.render(bio_to_spacy_doc(tokens, pred_labels), style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c759cf",
   "metadata": {},
   "source": [
    "## 7 · Conclusiones y trabajo futuro\n",
    "- Resume fortalezas y limitaciones de cada método.\n",
    "- Sugiere cómo mejoraría un **sistema híbrido** (p. ej. reglas específicas para fechas + modelo para el resto).\n",
    "- ¿Qué pasos seguirías para adaptar el modelo a un dominio clínico?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930b2c17",
   "metadata": {},
   "source": [
    "---\n",
    "### Créditos\n",
    "- CoNLL‑2002 Shared Task: <https://www.clips.uantwerpen.be/conll2002/ner/>\n",
    "- Modelo BERT‑NER en español: <https://huggingface.co/mrm8488/bert-spanish-cased-finetuned-ner>\n",
    "\n",
    "© 2025 – Elaborado para la clase de **Algoritmos Supervisados y Anotación para PLN**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
