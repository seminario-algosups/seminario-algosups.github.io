{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b826b6a",
   "metadata": {},
   "source": [
    "### Sugerencias de uso de la Notebook: \n",
    "- Sugerimos 'Abrir en Colab' y realizar una copia del cuaderno antes de usarlo.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/seminario-algosups/seminario-algosups.github.io/blob/master/Clase-13/clase13.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1341f8b7",
   "metadata": {},
   "source": [
    "# Analisis de sentimiento\n",
    "\n",
    "El an√°lisis de sentimiento es una tarea de procesamiento del lenguaje natural que forma parte del amplio campo de las tareas de clasificaci√≥n de textos (*text classification*).\n",
    "\n",
    "La clasificaci√≥n de textos incluye adem√°s, entre otras tareas, la detecci√≥n de spam, la identificaci√≥n de idioma, la atribuci√≥n de autor√≠a y la detecci√≥n de t√≥picos (*topic detection*). M√°s recientemente, se incorpor√≥ el *toxicity detection*.\n",
    "\n",
    "El an√°lisis de sentimiento, puntualmente, consiste en determinar autom√°ticamente si un texto resulta positivo, neutral o negativo.\n",
    "\n",
    "Existen tres grandes enfoques:\n",
    "- *Enfoques l√©xicos*: Calculan el sentimiento en funci√≥n de la presencia o no de ciertas palabras predefinidas de antemano, como, por ejemplo, subjetivemas, negaci√≥n, predicados de gusto, etc. Est√°n basados en reglas, lo que los hace menos flexibles.\n",
    "- *Enfoques de aprendizaje autom√°tico*: Son mucho m√°s adecuados y flexibles, pero requieren de datos etiquetados.\n",
    "- *Aprendizaje profundo con transformers preentrenados*: Son el estado del arte actual, pero requieren muchos recursos computacionales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2af229",
   "metadata": {},
   "source": [
    "## Enfoques L√©xicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6075fcee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NEUTRO'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Simulamos diccionarios l√©xicos simples\n",
    "positivas = {\"feliz\", \"bueno\", \"excelente\", \"maravilloso\", \"fant√°stico\"}\n",
    "negativas = {\"malo\", \"horrible\", \"terrible\", \"feo\", \"asco\"}\n",
    "\n",
    "def analisis_lexico(texto):\n",
    "    tokens = texto.lower().split()\n",
    "    pos = sum(1 for t in tokens if t in positivas)\n",
    "    neg = sum(1 for t in tokens if t in negativas)\n",
    "    if pos > neg:\n",
    "        return \"POSITIVO\"\n",
    "    elif neg > pos:\n",
    "        return \"NEGATIVO\"\n",
    "    else:\n",
    "        return \"NEUTRO\"\n",
    "\n",
    "# Ejemplo\n",
    "analisis_lexico(\"El d√≠a fue maravilloso pero la comida estuvo horrible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5507a7",
   "metadata": {},
   "source": [
    "## Enfoques de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1434abcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07b683f94c2a4e0dad2c9e3bc09b0a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dataset_infos.json:   0%|          | 0.00/850 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d7ce1ce04048ce8c4f3e3ccfc2a965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(‚Ä¶)-00000-of-00001-24655419d6deaaaf.parquet:   0%|          | 0.00/83.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714569dc9fe14e87a198849e9b5b4cd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(‚Ä¶)-00000-of-00001-a29248be1c10e21c.parquet:   0%|          | 0.00/123k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7ea51360bfb44cdbd1026718cb96a1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1125 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8be7ce9b7edf4a0c885eee56ecbe443b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1706 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Cargar el dataset desde Hugging Face\n",
    "dataset = load_dataset(\"mrm8488/tass-2019\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a569b78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1125\n",
      "1706\n"
     ]
    }
   ],
   "source": [
    "dataset[\"train\"][0]  # Ver el primer ejemplo del dataset\n",
    "print(len(dataset[\"train\"]))  # Ver el n√∫mero de ejemplos en el dataset\n",
    "print(len(dataset[\"test\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c82162c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': [0, 1, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      " 'sentence': ['@myendlesshazza a. que puto mal escribo b. me sigo surrando '\n",
      "              'help 3. ha quedado raro el \"c√≥metelo\" ah√≠ JAJAJAJA',\n",
      "              'Quiero mogoll√≥n a @AlbaBenito99 pero sobretodo por lo r√°pido '\n",
      "              'que contesta a los wasaps',\n",
      "              'Vale he visto la tia bebiendose su regla y me hs dado muchs '\n",
      "              'grima',\n",
      "              '@Yulian_Poe @guillermoterry1 Ah. mucho m√°s por supuesto! solo '\n",
      "              'que lo incluyo. Me hab√≠as entendido mal',\n",
      "              '@toNi_end seria mejor que dejasen de emitir esa basura ya  hay '\n",
      "              'que evolucionar para bien y eso',\n",
      "              '@jonoro96 te mandaria a comprarte un burro, pero no creo que '\n",
      "              'hayan tiendas abiertas ahora',\n",
      "              '@hywzz la voz de Mar√≠a al final me mata JAJAJSJAJAJAJ quilla y '\n",
      "              'yo que',\n",
      "              '@mendescodes @heroinseb enserio cuando hab√©is dicho que los '\n",
      "              'froot loops est√°n malos me ha dolido...',\n",
      "              'Oye @luciaskaa te pones a hablar con @josecs02 como en los '\n",
      "              'viejos tiempos y no avisas  @JuanAlfonso251 @CrisDazGar',\n",
      "              '@JCLilGangster yo tengo que aguantar 4 ni√±os peque√±os, no s√© '\n",
      "              'que es peor'],\n",
      " 'sentiments': ['N', 'P', 'N', 'P', 'N', 'N', 'N', 'N', 'N', 'N']}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(dataset[\"train\"][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c41cf440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "0    474\n",
       "1    354\n",
       "2    157\n",
       "3    140\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#sampled = dataset[\"train\"].train_test_split(test_size=0.5, seed=42)[\"test\"]\n",
    "#print(f\"N√∫mero de ejemplos muestreados: {len(sampled)}\")\n",
    "#print(sampled[0])\n",
    "\n",
    "# Convertir a DataFrame\n",
    "df = pd.DataFrame(dataset[\"train\"])\n",
    "df = df[[\"sentence\", \"labels\"]].dropna()\n",
    "\n",
    "# Ver etiquetas √∫nicas\n",
    "df[\"labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf12c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df[\"sentence\"])\n",
    "y = df[\"labels\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7b0a4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.90      0.65       143\n",
      "           1       0.56      0.42      0.48       102\n",
      "           2       0.00      0.00      0.00        49\n",
      "           3       0.00      0.00      0.00        44\n",
      "\n",
      "    accuracy                           0.51       338\n",
      "   macro avg       0.27      0.33      0.28       338\n",
      "weighted avg       0.38      0.51      0.42       338\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfc736cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "textos = [\n",
    "    \"Me encanta este producto\", \"Odio este lugar\",\n",
    "    \"La pel√≠cula fue buena\", \"Es horrible y lento\",\n",
    "    \"Excelente atenci√≥n\", \"Mal√≠simo todo\", \"La comida estuvo bien, la atenci√≥n podria mejorar bastante\"\n",
    "]\n",
    "# Probar con el ds original!!\n",
    "etiquetas = [\"pos\", \"neg\", \"pos\", \"neg\", \"pos\", \"neg\", \"neg\"]\n",
    "# 0: neg, # 1: pos\n",
    "df_testeos = pd.DataFrame({\"text\": textos, \"label\": etiquetas})\n",
    "\n",
    "df_testeos[\"pred\"] = clf.predict(vectorizer.transform(df_testeos[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b477b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Me encanta este producto</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Odio este lugar</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>La pel√≠cula fue buena</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Es horrible y lento</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Excelente atenci√≥n</td>\n",
       "      <td>pos</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mal√≠simo todo</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>La comida estuvo bien, la atenci√≥n podria mejo...</td>\n",
       "      <td>neg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label  pred\n",
       "0                           Me encanta este producto   pos     1\n",
       "1                                    Odio este lugar   neg     0\n",
       "2                              La pel√≠cula fue buena   pos     1\n",
       "3                                Es horrible y lento   neg     0\n",
       "4                                 Excelente atenci√≥n   pos     0\n",
       "5                                      Mal√≠simo todo   neg     0\n",
       "6  La comida estuvo bien, la atenci√≥n podria mejo...   neg     1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_testeos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a5b8fd",
   "metadata": {},
   "source": [
    "## Modelos basados en Transformers: \n",
    "1. Verificado\n",
    "2. PySentimiento\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a70dedfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a7184c1427248b99aef35ee9bc6a52d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/785 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae19e1097a44b9b858cf447fae40fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/439M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e19d282525be4bbb83b7d3335cb1044e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f16120bc7f54651b7529c09b78f1c60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b01386998e4e48adb25dc6ba289158f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto: Me encanta este producto -> Etiqueta: Positive, Score: 0.9998\n",
      "Texto: Odio este lugar -> Etiqueta: Negative, Score: 0.9995\n",
      "Texto: La pel√≠cula fue buena -> Etiqueta: Positive, Score: 0.9997\n",
      "Texto: Es horrible y lento -> Etiqueta: Negative, Score: 0.9995\n",
      "Texto: Excelente atenci√≥n -> Etiqueta: Positive, Score: 0.9997\n",
      "Texto: Mal√≠simo todo -> Etiqueta: Negative, Score: 0.9877\n",
      "Texto: La comida estuvo bien, la atenci√≥n podria mejorar bastante -> Etiqueta: Positive, Score: 0.9995\n"
     ]
    }
   ],
   "source": [
    "# Usando un modelo preentrenado de Hugging Face para an√°lisis de sentimientos\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"VerificadoProfesional/SaBERT-Spanish-Sentiment-Analysis\")\n",
    "\n",
    "for texto in textos:\n",
    "    resultado = pipe(texto)\n",
    "    print(f\"Texto: {texto} -> Etiqueta: {resultado[0]['label']}, Score: {resultado[0]['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6671da",
   "metadata": {},
   "source": [
    "## PySentimiento: An√°lisis de Opini√≥n y NLP Social Multiling√ºe\n",
    "\n",
    "`pysentimiento` es una biblioteca de Python que ofrece modelos preentrenados para tareas de procesamiento de lenguaje natural centradas en redes sociales. Es compatible con varios idiomas (espa√±ol, ingl√©s, portugu√©s, italiano) y permite realizar an√°lisis de sentimiento, detecci√≥n de emociones, discurso de odio, iron√≠a, an√°lisis de entidades nombradas (NER), y etiquetas gramaticales (POS).\n",
    "\n",
    "A continuaci√≥n, se muestran ejemplos de uso con texto en espa√±ol.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f502726",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instalar pysentimiento (si no est√° instalado)\n",
    "#!pip install pysentimiento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065db2e4",
   "metadata": {},
   "source": [
    "## Flujo: del texto a la predicci√≥n\n",
    "\n",
    "Para entender c√≥mo funciona internamente la herramienta, aqu√≠ se describe el pipeline t√≠pico que ocurre al llamar `analyzer.predict(text)`:\n",
    "\n",
    "### 1. Preprocesamiento\n",
    "El texto crudo se pasa primero por el preprocesador de tweets (a menos que est√© deshabilitado). Este paso limpia el texto aplicando reglas como la normalizaci√≥n de menciones y URLs, la reducci√≥n de repeticiones de caracteres, la conversi√≥n de emojis a texto, etc. El resultado es una versi√≥n normalizada del texto de entrada.\n",
    "\n",
    "### 2. Tokenizaci√≥n\n",
    "El tokenizador del analizador (una subclase de `AutoTokenizer` de Hugging Face) convierte el texto preprocesado en una secuencia de tokens/IDs que el modelo Transformer puede interpretar. Esto incluye dividir el texto en subpalabras y agregar tokens especiales (como `[CLS]` y `[SEP]` para BERT, o solo tokens de inicio/fin en el caso de RoBERTa). Tambi√©n se realiza padding o truncamiento seg√∫n la longitud m√°xima permitida.\n",
    "\n",
    "### 3. Inferencia del Modelo\n",
    "Los IDs de tokens se env√≠an al modelo Transformer (que internamente es un modelo de PyTorch). Dependiendo de la tarea:\n",
    "\n",
    "- **Tareas de clasificaci√≥n:** El modelo produce un conjunto de logits (puntuaciones no normalizadas) para cada clase. Por ejemplo, el modelo de sentimiento devuelve tres logits (uno por cada clase: POS, NEG, NEU).\n",
    "- **Tareas multi-etiqueta:** El modelo devuelve un logit por cada etiqueta posible (por ejemplo, tres logits para las etiquetas de discurso de odio: `hateful`, `targeted`, `aggressive`).\n",
    "- **Tareas de etiquetado secuencial (NER/POS):** Se devuelve un logit por token por cada posible etiqueta.\n",
    "\n",
    "### 4. Post-procesamiento de la Predicci√≥n\n",
    "Los logits producidos por el modelo se convierten en probabilidades:\n",
    "\n",
    "- Para clasificaci√≥n de una sola etiqueta, se aplica **softmax**, y se selecciona la etiqueta con mayor probabilidad como `output`.\n",
    "- Para clasificaci√≥n multi-etiqueta (como discurso de odio), se aplica **sigmoid** a cada logit, y se seleccionan las etiquetas cuya probabilidad supera un umbral (por defecto, 0.5).\n",
    "\n",
    "\n",
    "Luego, las etiquetas seleccionadas se ensamblan en un objeto 'resultado'.\n",
    "\n",
    "### 5. Formato de Salida\n",
    "El resultado se devuelve como un objeto `AnalyzerOutput` (o una lista si se procesan m√∫ltiples textos). Este objeto contiene:\n",
    "\n",
    "- `output`: la etiqueta predicha (para tareas de una sola etiqueta) o una lista de etiquetas (para tareas multi-etiqueta). En tareas secuenciales como NER o POS, puede ser una lista de anotaciones por token.\n",
    "- `probas`: un diccionario que asigna a cada etiqueta su probabilidad estimada.  \n",
    "  Por ejemplo:\n",
    "  ```python\n",
    "  {'POS': 0.998, 'NEG': 0.002, 'NEU': 0.000}\n",
    "  ```\n",
    "  para una oraci√≥n claramente positiva, o:\n",
    "  ```python\n",
    "  {'hateful': 0.987, 'targeted': 0.978, 'aggressive': 0.969}\n",
    "  ```\n",
    "  ppara un texto con discurso de odio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b5046a",
   "metadata": {},
   "source": [
    "## Veamos algunos Ejemplos de funcionalidades\n",
    "\n",
    "Tras la instalaci√≥n, el uso de la biblioteca es muy sencillo. \n",
    "\n",
    "Se crea un analizador para la tarea y el idioma de inter√©s y, a continuaci√≥n, se llama a la funcion 'predict' con nuevos textos. \n",
    "\n",
    "En este caso definimos como tarea el an√°lisis de sentimiento y el idioma que queremos usar como espa√±ol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "506fecff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c8ebf075a624b70b8f62d00556022e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/925 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3c7dd16fcb5499c94e7f6208cbcd1db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/435M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4317e2c32b374bf4b25f204d23afee82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/384 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43bb6955d0f74cdbbabff2be17c8d504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f47753556af94f2c90619611adcb9be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/167 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from pysentimiento import create_analyzer\n",
    "\n",
    "\n",
    "# Analizador de sentimiento en espa√±ol\n",
    "sentiment_analyzer = create_analyzer(task=\"sentiment\", lang=\"es\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebba23b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positivo: AnalyzerOutput(output=POS, probas={POS: 0.946, NEU: 0.037, NEG: 0.017})\n",
      "Negativo: AnalyzerOutput(output=NEG, probas={NEG: 0.887, NEU: 0.098, POS: 0.014})\n",
      "Neutro: AnalyzerOutput(output=NEU, probas={NEU: 0.847, POS: 0.092, NEG: 0.060})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "texto_positivo = \"Qu√© gran jugador es Messi\"\n",
    "texto_negativo = \"Esto es p√©simo\"\n",
    "texto_neutro = \"El evento ser√° a las 5 PM\"\n",
    "\n",
    "print(\"Positivo:\", sentiment_analyzer.predict(texto_positivo))\n",
    "print(\"Negativo:\", sentiment_analyzer.predict(texto_negativo))\n",
    "print(\"Neutro:\", sentiment_analyzer.predict(texto_neutro))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41c1159",
   "metadata": {},
   "source": [
    "## Emotion Analysis\n",
    "\n",
    "`pysentimiento` provee an√°lisis de emociones a trav√©s de modelos pre-entrenados con los datasets de [EmoEvent](https://github.com/fmplaza/EmoEvent-multilingual-corpus/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f746f16e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c197632c441a4cb7a70a0d46686864ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7190d22c5763464189edd56eccddbd3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/435M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2027ab5e03144c8b73b5116aee3b16d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/384 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80ed707efffa40c6b838abb2ee2a7983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c98b8b2e634e19aab2703adf5921fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/435M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d9fefad2bd4471fbda204da915805ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/167 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emoci√≥n: AnalyzerOutput(output=joy, probas={joy: 0.991, surprise: 0.003, others: 0.002, fear: 0.001, disgust: 0.001, sadness: 0.001, anger: 0.000})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "emotion_analyzer = create_analyzer(task=\"emotion\", lang=\"es\")\n",
    "\n",
    "print(\"Emoci√≥n:\", emotion_analyzer.predict(\"Estoy muy feliz con el resultado\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5da67b3",
   "metadata": {},
   "source": [
    "## Hate Speech\n",
    "Replicamos la operaci√≥n pero esta ver para an√°lissi de odio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06713a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49a4298743b84bc68d81f1fac3ae5bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/956 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4a0dc097a0e4e3e97c329dc4d116139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/435M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4525469b9184c91b52a9c6c4f9335f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/384 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f249feefb142ea84d4e655247c8dd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff2ad9ab2c543cbb175d77eae168d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/435M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd3b6a71f2bd46f3847fd258d5139adb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/167 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discurso de odio: AnalyzerOutput(output=['hateful', 'targeted', 'aggressive'], probas={hateful: 0.987, targeted: 0.987, aggressive: 0.973})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hate_analyzer = create_analyzer(task=\"hate_speech\", lang=\"es\")\n",
    "\n",
    "texto_odio = \"Vaya guarra barata y de poca monta es XXXX!\"\n",
    "print(\"Discurso de odio:\", hate_analyzer.predict(texto_odio))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "212b77e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cbc5867793840069bb7f5c6e91d4664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/915 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "085b042941384265bead71935d7829f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/435M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3239f9a705d14aa592802c25541b991f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/384 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef3fd33872ad4430b939f82aa0b3d21e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afedc9da4b124b18bb2ba25b01e02d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/435M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a3098040f5441ecba1b860d28b04882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/167 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iron√≠a: AnalyzerOutput(output=ironic, probas={ironic: 0.811, not ironic: 0.189})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "irony_analyzer = create_analyzer(task=\"irony\", lang=\"es\")\n",
    "\n",
    "texto_ironia = \"S√≠ claro, como si el gobierno alguna vez resolviera algo...\"\n",
    "print(\"Iron√≠a:\", irony_analyzer.predict(texto_ironia))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81956d31",
   "metadata": {},
   "source": [
    "## Token Labeling tasks\n",
    "\n",
    "\n",
    "`pysentimiento` cuenta con analizadores para POS tagging & NER gracias al dataset multilingual [LinCE](https://ritual.uh.edu/lince/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b167eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto original: @usuario deber√≠as ver esto http://bit.ly/ejemplo jajajajajaja\n",
      "Preprocesado: @usuario deber√≠as ver esto url jaja\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pysentimiento.preprocessing import preprocess_tweet\n",
    "\n",
    "texto_tweet = \"@usuario deber√≠as ver esto http://bit.ly/ejemplo jajajajajaja\"\n",
    "print(\"Texto original:\", texto_tweet)\n",
    "print(\"Preprocesado:\", preprocess_tweet(texto_tweet))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "001fa35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "580ccdef1b684a27a132aa9449b7fc5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7621d013b73846498d69bc0953213d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/433M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ddee7c634c4d47b89b18ed6d78de4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/334 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "835fa700ca4b49e4a15cee2682c4a146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/858k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61763790105142a2bb2d93509f341ede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/433M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f03c292efa13434db82ba8fbfa424038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entidades nombradas: TokenClassificationOutput(entities=[Lionel Messi (PER), Inter (GROUP), Miami (GROUP)], tokens=['Lionel', 'Messi', 'juega', 'en', 'el', 'Inter', 'de', 'Miami'], labels=['B-PER', 'I-PER', 'O', 'O', 'O', 'B-GROUP', 'O', 'I-GROUP'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ner_analyzer = create_analyzer(task=\"ner\", lang=\"es\")\n",
    "\n",
    "print(\"Entidades nombradas:\", ner_analyzer.predict(\"Lionel Messi juega en el Inter de Miami\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7d4aa14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb2c889f40141039de0aa2e93d9de0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7119cc2a92924f029b6e835520034af2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/433M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc4c1cda3324025ac645865aa38eb2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/330 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcbc36c30751472c9723b2029d1c70e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/829k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fda7ede761e54e2f96c70513afe97ddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS tagging: TokenClassificationOutput(tokens=['Messi', 'corre', 'r√°pidamente', 'con', 'el', 'bal√≥n'], labels=['PROPN', 'VERB', 'ADV', 'ADP', 'DET', 'NOUN'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pos_analyzer = create_analyzer(task=\"pos\", lang=\"es\")\n",
    "\n",
    "print(\"POS tagging:\", pos_analyzer.predict(\"Messi corre r√°pidamente con el bal√≥n\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bfa55a",
   "metadata": {},
   "source": [
    "\n",
    "## üß† Ejercicio: An√°lisis de Sentimientos y Emociones en Opiniones de Usuarios\n",
    "\n",
    "### üìù Objetivo\n",
    "Usar `pysentimiento` para analizar una serie de opiniones extra√≠das de redes sociales o rese√±as, y comparar los resultados obtenidos con la intuici√≥n humana. Reflexionar sobre aciertos, errores y posibles fuentes de ambig√ºedad.\n",
    "\n",
    "### üì¶ Materiales\n",
    "- Lista de 10 a 15 frases que simulen opiniones de usuarios (pueden ser reales o inventadas).\n",
    "- Un cuaderno (notebook) en Colab o Jupyter con `pysentimiento` instalado.\n",
    "\n",
    "### üîß Instrucciones\n",
    "\n",
    "1. **Preparaci√≥n del Dataset**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b2b184",
   "metadata": {},
   "outputs": [],
   "source": [
    "opiniones = [\n",
    "       \"Me encant√≥ la atenci√≥n al cliente, volver√≠a sin dudarlo.\",\n",
    "       \"Una p√©rdida de tiempo, el producto no sirve.\",\n",
    "       \"El hotel estaba bien, aunque el desayuno era mejorable.\",\n",
    "       \"No s√© qu√© pensar, fue una experiencia rara.\",\n",
    "       \"¬°Excelente servicio y muy r√°pido!\",\n",
    "       \"Demasiado caro para lo que ofrece.\",\n",
    "       \"No me gust√≥, pero entiendo que a otros s√≠.\",\n",
    "       \"La pel√≠cula fue una joya, me hizo llorar de emoci√≥n.\",\n",
    "       \"Malisimo, no lo recomiendo a nadie.\",\n",
    "       \"La app est√° bien dise√±ada, pero falla mucho.\"\n",
    "   ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3692703e",
   "metadata": {},
   "source": [
    "## 2. Predicci√≥n autom√°tica con PySentimiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a1fafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysentimiento import create_analyzer\n",
    "\n",
    "sentiment_analyzer = create_analyzer(task=\"sentiment\", lang=\"es\")\n",
    "emotion_analyzer = create_analyzer(task=\"emotion\", lang=\"es\")\n",
    "\n",
    "for frase in opiniones:\n",
    "    sentimiento = sentiment_analyzer.predict(frase)\n",
    "    emocion = emotion_analyzer.predict(frase)\n",
    "    print(f\"Frase: {frase}\")\n",
    "    print(f\"  ‚û§ Sentimiento: {sentimiento.output}, probabilidades: {sentimiento.probas}\")\n",
    "    print(f\"  ‚û§ Emoci√≥n: {emocion.output}, probabilidades: {emocion.probas}\")\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218a8495",
   "metadata": {},
   "source": [
    "### Tareas a realizar\n",
    "\n",
    "üßê Clasificar cada frase como positiva, negativa o neutra antes de ejecutar el modelo. Luego comparalo con la predicci√≥n autom√°tica.\n",
    "\n",
    "‚ùì ¬øCoincide tu intuici√≥n con la del modelo? ¬øEn qu√© casos no? ¬øPor qu√© podr√≠a fallar el modelo?\n",
    "\n",
    "üí° Observar los casos donde el modelo predice neutral. ¬øTe parece apropiado? ¬øQu√© tipo de lenguaje aparece all√≠?\n",
    "\n",
    "üîç Revisar tambi√©n las emociones detectadas. ¬øHay ambig√ºedad? ¬øCaptura bien la emoci√≥n dominante?\n",
    "\n",
    "üß™ Modificar algunas frases para ver c√≥mo cambian las predicciones. Por ejemplo: \"El servicio fue incre√≠blemente lento\" vs. \"El servicio fue lento, pero aceptable\".\n",
    "\n",
    "## Reflexi√≥n Final\n",
    "\n",
    "¬øQu√© fortalezas y limitaciones encontraste en el modelo?\n",
    "\n",
    "¬øQu√© tipos de sesgos podr√≠an surgir si solo usamos este tipo de modelos para tomar decisiones?\n",
    "\n",
    "¬øC√≥mo mejorar√≠as este pipeline para un caso de uso real, como popr ej. para  monitorear opiniones sobre una marca?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ecaea2",
   "metadata": {},
   "source": [
    "   \n",
    "Para m√°s informaci√≥n: [https://github.com/pysentimiento/pysentimiento](https://github.com/pysentimiento/pysentimiento)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
