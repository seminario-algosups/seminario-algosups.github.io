{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b826b6a",
   "metadata": {},
   "source": [
    "### Sugerencias de uso de la Notebook: \n",
    "- Sugerimos 'Abrir en Colab' y realizar una copia del cuaderno antes de usarlo.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/seminario-algosups/seminario-algosups.github.io/blob/master/Clase-13/clase13.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1341f8b7",
   "metadata": {},
   "source": [
    "# Analisis de sentimiento\n",
    "\n",
    "El análisis de sentimiento es una tarea de procesamiento del lenguaje natural que forma parte del amplio campo de las tareas de clasificación de textos (*text classification*).\n",
    "\n",
    "La clasificación de textos incluye además, entre otras tareas, la detección de spam, la identificación de idioma, la atribución de autoría y la detección de tópicos (*topic detection*). Más recientemente, se incorporó el *toxicity detection*.\n",
    "\n",
    "El análisis de sentimiento, puntualmente, consiste en determinar automáticamente si un texto resulta positivo, neutral o negativo.\n",
    "\n",
    "Existen tres grandes enfoques:\n",
    "- *Enfoques léxicos*: Calculan el sentimiento en función de la presencia o no de ciertas palabras predefinidas de antemano, como, por ejemplo, subjetivemas, negación, predicados de gusto, etc. Están basados en reglas, lo que los hace menos flexibles.\n",
    "- *Enfoques de aprendizaje automático*: Son mucho más adecuados y flexibles, pero requieren de datos etiquetados.\n",
    "- *Aprendizaje profundo con transformers preentrenados*: Son el estado del arte actual, pero requieren muchos recursos computacionales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2af229",
   "metadata": {},
   "source": [
    "## Enfoques Léxicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6075fcee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NEUTRO'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Simulamos diccionarios léxicos simples\n",
    "positivas = {\"feliz\", \"bueno\", \"excelente\", \"maravilloso\", \"fantástico\"}\n",
    "negativas = {\"malo\", \"horrible\", \"terrible\", \"feo\", \"asco\"}\n",
    "\n",
    "def analisis_lexico(texto):\n",
    "    tokens = texto.lower().split()\n",
    "    pos = sum(1 for t in tokens if t in positivas)\n",
    "    neg = sum(1 for t in tokens if t in negativas)\n",
    "    if pos > neg:\n",
    "        return \"POSITIVO\"\n",
    "    elif neg > pos:\n",
    "        return \"NEGATIVO\"\n",
    "    else:\n",
    "        return \"NEUTRO\"\n",
    "\n",
    "# Ejemplo\n",
    "analisis_lexico(\"El día fue maravilloso pero la comida estuvo horrible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5507a7",
   "metadata": {},
   "source": [
    "## Enfoques de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1434abcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07b683f94c2a4e0dad2c9e3bc09b0a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dataset_infos.json:   0%|          | 0.00/850 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d7ce1ce04048ce8c4f3e3ccfc2a965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-24655419d6deaaaf.parquet:   0%|          | 0.00/83.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714569dc9fe14e87a198849e9b5b4cd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-a29248be1c10e21c.parquet:   0%|          | 0.00/123k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7ea51360bfb44cdbd1026718cb96a1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1125 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8be7ce9b7edf4a0c885eee56ecbe443b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1706 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Cargar el dataset desde Hugging Face\n",
    "dataset = load_dataset(\"mrm8488/tass-2019\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a569b78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1125\n",
      "1706\n"
     ]
    }
   ],
   "source": [
    "dataset[\"train\"][0]  # Ver el primer ejemplo del dataset\n",
    "print(len(dataset[\"train\"]))  # Ver el número de ejemplos en el dataset\n",
    "print(len(dataset[\"test\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c82162c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': [0, 1, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      " 'sentence': ['@myendlesshazza a. que puto mal escribo b. me sigo surrando '\n",
      "              'help 3. ha quedado raro el \"cómetelo\" ahí JAJAJAJA',\n",
      "              'Quiero mogollón a @AlbaBenito99 pero sobretodo por lo rápido '\n",
      "              'que contesta a los wasaps',\n",
      "              'Vale he visto la tia bebiendose su regla y me hs dado muchs '\n",
      "              'grima',\n",
      "              '@Yulian_Poe @guillermoterry1 Ah. mucho más por supuesto! solo '\n",
      "              'que lo incluyo. Me habías entendido mal',\n",
      "              '@toNi_end seria mejor que dejasen de emitir esa basura ya  hay '\n",
      "              'que evolucionar para bien y eso',\n",
      "              '@jonoro96 te mandaria a comprarte un burro, pero no creo que '\n",
      "              'hayan tiendas abiertas ahora',\n",
      "              '@hywzz la voz de María al final me mata JAJAJSJAJAJAJ quilla y '\n",
      "              'yo que',\n",
      "              '@mendescodes @heroinseb enserio cuando habéis dicho que los '\n",
      "              'froot loops están malos me ha dolido...',\n",
      "              'Oye @luciaskaa te pones a hablar con @josecs02 como en los '\n",
      "              'viejos tiempos y no avisas  @JuanAlfonso251 @CrisDazGar',\n",
      "              '@JCLilGangster yo tengo que aguantar 4 niños pequeños, no sé '\n",
      "              'que es peor'],\n",
      " 'sentiments': ['N', 'P', 'N', 'P', 'N', 'N', 'N', 'N', 'N', 'N']}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(dataset[\"train\"][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c41cf440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "0    474\n",
       "1    354\n",
       "2    157\n",
       "3    140\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#sampled = dataset[\"train\"].train_test_split(test_size=0.5, seed=42)[\"test\"]\n",
    "#print(f\"Número de ejemplos muestreados: {len(sampled)}\")\n",
    "#print(sampled[0])\n",
    "\n",
    "# Convertir a DataFrame\n",
    "df = pd.DataFrame(dataset[\"train\"])\n",
    "df = df[[\"sentence\", \"labels\"]].dropna()\n",
    "\n",
    "# Ver etiquetas únicas\n",
    "df[\"labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf12c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df[\"sentence\"])\n",
    "y = df[\"labels\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7b0a4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.90      0.65       143\n",
      "           1       0.56      0.42      0.48       102\n",
      "           2       0.00      0.00      0.00        49\n",
      "           3       0.00      0.00      0.00        44\n",
      "\n",
      "    accuracy                           0.51       338\n",
      "   macro avg       0.27      0.33      0.28       338\n",
      "weighted avg       0.38      0.51      0.42       338\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfc736cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "textos = [\n",
    "    \"Me encanta este producto\", \"Odio este lugar\",\n",
    "    \"La película fue buena\", \"Es horrible y lento\",\n",
    "    \"Excelente atención\", \"Malísimo todo\", \"La comida estuvo bien, la atención podria mejorar bastante\"\n",
    "]\n",
    "# Probar con el ds original!!\n",
    "etiquetas = [\"pos\", \"neg\", \"pos\", \"neg\", \"pos\", \"neg\", \"neg\"]\n",
    "# 0: neg, # 1: pos\n",
    "df_testeos = pd.DataFrame({\"text\": textos, \"label\": etiquetas})\n",
    "\n",
    "df_testeos[\"pred\"] = clf.predict(vectorizer.transform(df_testeos[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b477b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Me encanta este producto</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Odio este lugar</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>La película fue buena</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Es horrible y lento</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Excelente atención</td>\n",
       "      <td>pos</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Malísimo todo</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>La comida estuvo bien, la atención podria mejo...</td>\n",
       "      <td>neg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label  pred\n",
       "0                           Me encanta este producto   pos     1\n",
       "1                                    Odio este lugar   neg     0\n",
       "2                              La película fue buena   pos     1\n",
       "3                                Es horrible y lento   neg     0\n",
       "4                                 Excelente atención   pos     0\n",
       "5                                      Malísimo todo   neg     0\n",
       "6  La comida estuvo bien, la atención podria mejo...   neg     1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_testeos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a5b8fd",
   "metadata": {},
   "source": [
    "## Modelos basados en Transformers: \n",
    "1. Verificado\n",
    "2. PySentimiento\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a70dedfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a7184c1427248b99aef35ee9bc6a52d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/785 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae19e1097a44b9b858cf447fae40fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/439M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e19d282525be4bbb83b7d3335cb1044e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f16120bc7f54651b7529c09b78f1c60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b01386998e4e48adb25dc6ba289158f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto: Me encanta este producto -> Etiqueta: Positive, Score: 0.9998\n",
      "Texto: Odio este lugar -> Etiqueta: Negative, Score: 0.9995\n",
      "Texto: La película fue buena -> Etiqueta: Positive, Score: 0.9997\n",
      "Texto: Es horrible y lento -> Etiqueta: Negative, Score: 0.9995\n",
      "Texto: Excelente atención -> Etiqueta: Positive, Score: 0.9997\n",
      "Texto: Malísimo todo -> Etiqueta: Negative, Score: 0.9877\n",
      "Texto: La comida estuvo bien, la atención podria mejorar bastante -> Etiqueta: Positive, Score: 0.9995\n"
     ]
    }
   ],
   "source": [
    "# Usando un modelo preentrenado de Hugging Face para análisis de sentimientos\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"VerificadoProfesional/SaBERT-Spanish-Sentiment-Analysis\")\n",
    "\n",
    "for texto in textos:\n",
    "    resultado = pipe(texto)\n",
    "    print(f\"Texto: {texto} -> Etiqueta: {resultado[0]['label']}, Score: {resultado[0]['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6671da",
   "metadata": {},
   "source": [
    "## PySentimiento: Análisis de Opinión y NLP Social Multilingüe\n",
    "\n",
    "`pysentimiento` es una biblioteca de Python que ofrece modelos preentrenados para tareas de procesamiento de lenguaje natural centradas en redes sociales. Es compatible con varios idiomas (español, inglés, portugués, italiano) y permite realizar análisis de sentimiento, detección de emociones, discurso de odio, ironía, análisis de entidades nombradas (NER), y etiquetas gramaticales (POS).\n",
    "\n",
    "A continuación, se muestran ejemplos de uso con texto en español.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f502726",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instalar pysentimiento (si no está instalado)\n",
    "#!pip install pysentimiento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065db2e4",
   "metadata": {},
   "source": [
    "## Flujo: del texto a la predicción\n",
    "\n",
    "Para entender cómo funciona internamente la herramienta, aquí se describe el pipeline típico que ocurre al llamar `analyzer.predict(text)`:\n",
    "\n",
    "### 1. Preprocesamiento\n",
    "El texto crudo se pasa primero por el preprocesador de tweets (a menos que esté deshabilitado). Este paso limpia el texto aplicando reglas como la normalización de menciones y URLs, la reducción de repeticiones de caracteres, la conversión de emojis a texto, etc. El resultado es una versión normalizada del texto de entrada.\n",
    "\n",
    "### 2. Tokenización\n",
    "El tokenizador del analizador (una subclase de `AutoTokenizer` de Hugging Face) convierte el texto preprocesado en una secuencia de tokens/IDs que el modelo Transformer puede interpretar. Esto incluye dividir el texto en subpalabras y agregar tokens especiales (como `[CLS]` y `[SEP]` para BERT, o solo tokens de inicio/fin en el caso de RoBERTa). También se realiza padding o truncamiento según la longitud máxima permitida.\n",
    "\n",
    "### 3. Inferencia del Modelo\n",
    "Los IDs de tokens se envían al modelo Transformer (que internamente es un modelo de PyTorch). Dependiendo de la tarea:\n",
    "\n",
    "- **Tareas de clasificación:** El modelo produce un conjunto de logits (puntuaciones no normalizadas) para cada clase. Por ejemplo, el modelo de sentimiento devuelve tres logits (uno por cada clase: POS, NEG, NEU).\n",
    "- **Tareas multi-etiqueta:** El modelo devuelve un logit por cada etiqueta posible (por ejemplo, tres logits para las etiquetas de discurso de odio: `hateful`, `targeted`, `aggressive`).\n",
    "- **Tareas de etiquetado secuencial (NER/POS):** Se devuelve un logit por token por cada posible etiqueta.\n",
    "\n",
    "### 4. Post-procesamiento de la Predicción\n",
    "Los logits producidos por el modelo se convierten en probabilidades:\n",
    "\n",
    "- Para clasificación de una sola etiqueta, se aplica **softmax**, y se selecciona la etiqueta con mayor probabilidad como `output`.\n",
    "- Para clasificación multi-etiqueta (como discurso de odio), se aplica **sigmoid** a cada logit, y se seleccionan las etiquetas cuya probabilidad supera un umbral (por defecto, 0.5).\n",
    "\n",
    "\n",
    "Luego, las etiquetas seleccionadas se ensamblan en un objeto 'resultado'.\n",
    "\n",
    "### 5. Formato de Salida\n",
    "El resultado se devuelve como un objeto `AnalyzerOutput` (o una lista si se procesan múltiples textos). Este objeto contiene:\n",
    "\n",
    "- `output`: la etiqueta predicha (para tareas de una sola etiqueta) o una lista de etiquetas (para tareas multi-etiqueta). En tareas secuenciales como NER o POS, puede ser una lista de anotaciones por token.\n",
    "- `probas`: un diccionario que asigna a cada etiqueta su probabilidad estimada.  \n",
    "  Por ejemplo:\n",
    "  ```python\n",
    "  {'POS': 0.998, 'NEG': 0.002, 'NEU': 0.000}\n",
    "  ```\n",
    "  para una oración claramente positiva, o:\n",
    "  ```python\n",
    "  {'hateful': 0.987, 'targeted': 0.978, 'aggressive': 0.969}\n",
    "  ```\n",
    "  ppara un texto con discurso de odio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b5046a",
   "metadata": {},
   "source": [
    "## Veamos algunos Ejemplos de funcionalidades\n",
    "\n",
    "Tras la instalación, el uso de la biblioteca es muy sencillo. \n",
    "\n",
    "Se crea un analizador para la tarea y el idioma de interés y, a continuación, se llama a la funcion 'predict' con nuevos textos. \n",
    "\n",
    "En este caso definimos como tarea el análisis de sentimiento y el idioma que queremos usar como español\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "506fecff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c8ebf075a624b70b8f62d00556022e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/925 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3c7dd16fcb5499c94e7f6208cbcd1db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/435M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4317e2c32b374bf4b25f204d23afee82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/384 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43bb6955d0f74cdbbabff2be17c8d504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f47753556af94f2c90619611adcb9be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/167 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from pysentimiento import create_analyzer\n",
    "\n",
    "\n",
    "# Analizador de sentimiento en español\n",
    "sentiment_analyzer = create_analyzer(task=\"sentiment\", lang=\"es\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebba23b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positivo: AnalyzerOutput(output=POS, probas={POS: 0.946, NEU: 0.037, NEG: 0.017})\n",
      "Negativo: AnalyzerOutput(output=NEG, probas={NEG: 0.887, NEU: 0.098, POS: 0.014})\n",
      "Neutro: AnalyzerOutput(output=NEU, probas={NEU: 0.847, POS: 0.092, NEG: 0.060})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "texto_positivo = \"Qué gran jugador es Messi\"\n",
    "texto_negativo = \"Esto es pésimo\"\n",
    "texto_neutro = \"El evento será a las 5 PM\"\n",
    "\n",
    "print(\"Positivo:\", sentiment_analyzer.predict(texto_positivo))\n",
    "print(\"Negativo:\", sentiment_analyzer.predict(texto_negativo))\n",
    "print(\"Neutro:\", sentiment_analyzer.predict(texto_neutro))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41c1159",
   "metadata": {},
   "source": [
    "## Emotion Analysis\n",
    "\n",
    "`pysentimiento` provee análisis de emociones a través de modelos pre-entrenados con los datasets de [EmoEvent](https://github.com/fmplaza/EmoEvent-multilingual-corpus/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f746f16e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c197632c441a4cb7a70a0d46686864ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7190d22c5763464189edd56eccddbd3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/435M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2027ab5e03144c8b73b5116aee3b16d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/384 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80ed707efffa40c6b838abb2ee2a7983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c98b8b2e634e19aab2703adf5921fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/435M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d9fefad2bd4471fbda204da915805ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/167 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emoción: AnalyzerOutput(output=joy, probas={joy: 0.991, surprise: 0.003, others: 0.002, fear: 0.001, disgust: 0.001, sadness: 0.001, anger: 0.000})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "emotion_analyzer = create_analyzer(task=\"emotion\", lang=\"es\")\n",
    "\n",
    "print(\"Emoción:\", emotion_analyzer.predict(\"Estoy muy feliz con el resultado\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5da67b3",
   "metadata": {},
   "source": [
    "## Hate Speech\n",
    "Replicamos la operación pero esta ver para análissi de odio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06713a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49a4298743b84bc68d81f1fac3ae5bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/956 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4a0dc097a0e4e3e97c329dc4d116139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/435M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4525469b9184c91b52a9c6c4f9335f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/384 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f249feefb142ea84d4e655247c8dd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff2ad9ab2c543cbb175d77eae168d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/435M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd3b6a71f2bd46f3847fd258d5139adb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/167 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discurso de odio: AnalyzerOutput(output=['hateful', 'targeted', 'aggressive'], probas={hateful: 0.987, targeted: 0.987, aggressive: 0.973})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hate_analyzer = create_analyzer(task=\"hate_speech\", lang=\"es\")\n",
    "\n",
    "texto_odio = \"Vaya guarra barata y de poca monta es XXXX!\"\n",
    "print(\"Discurso de odio:\", hate_analyzer.predict(texto_odio))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "212b77e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cbc5867793840069bb7f5c6e91d4664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/915 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "085b042941384265bead71935d7829f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/435M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3239f9a705d14aa592802c25541b991f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/384 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef3fd33872ad4430b939f82aa0b3d21e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afedc9da4b124b18bb2ba25b01e02d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/435M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a3098040f5441ecba1b860d28b04882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/167 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ironía: AnalyzerOutput(output=ironic, probas={ironic: 0.811, not ironic: 0.189})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "irony_analyzer = create_analyzer(task=\"irony\", lang=\"es\")\n",
    "\n",
    "texto_ironia = \"Sí claro, como si el gobierno alguna vez resolviera algo...\"\n",
    "print(\"Ironía:\", irony_analyzer.predict(texto_ironia))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81956d31",
   "metadata": {},
   "source": [
    "## Token Labeling tasks\n",
    "\n",
    "\n",
    "`pysentimiento` cuenta con analizadores para POS tagging & NER gracias al dataset multilingual [LinCE](https://ritual.uh.edu/lince/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b167eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto original: @usuario deberías ver esto http://bit.ly/ejemplo jajajajajaja\n",
      "Preprocesado: @usuario deberías ver esto url jaja\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pysentimiento.preprocessing import preprocess_tweet\n",
    "\n",
    "texto_tweet = \"@usuario deberías ver esto http://bit.ly/ejemplo jajajajajaja\"\n",
    "print(\"Texto original:\", texto_tweet)\n",
    "print(\"Preprocesado:\", preprocess_tweet(texto_tweet))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "001fa35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "580ccdef1b684a27a132aa9449b7fc5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7621d013b73846498d69bc0953213d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/433M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ddee7c634c4d47b89b18ed6d78de4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/334 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "835fa700ca4b49e4a15cee2682c4a146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/858k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61763790105142a2bb2d93509f341ede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/433M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f03c292efa13434db82ba8fbfa424038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entidades nombradas: TokenClassificationOutput(entities=[Lionel Messi (PER), Inter (GROUP), Miami (GROUP)], tokens=['Lionel', 'Messi', 'juega', 'en', 'el', 'Inter', 'de', 'Miami'], labels=['B-PER', 'I-PER', 'O', 'O', 'O', 'B-GROUP', 'O', 'I-GROUP'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ner_analyzer = create_analyzer(task=\"ner\", lang=\"es\")\n",
    "\n",
    "print(\"Entidades nombradas:\", ner_analyzer.predict(\"Lionel Messi juega en el Inter de Miami\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7d4aa14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb2c889f40141039de0aa2e93d9de0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7119cc2a92924f029b6e835520034af2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/433M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc4c1cda3324025ac645865aa38eb2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/330 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcbc36c30751472c9723b2029d1c70e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/829k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fda7ede761e54e2f96c70513afe97ddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS tagging: TokenClassificationOutput(tokens=['Messi', 'corre', 'rápidamente', 'con', 'el', 'balón'], labels=['PROPN', 'VERB', 'ADV', 'ADP', 'DET', 'NOUN'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pos_analyzer = create_analyzer(task=\"pos\", lang=\"es\")\n",
    "\n",
    "print(\"POS tagging:\", pos_analyzer.predict(\"Messi corre rápidamente con el balón\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bfa55a",
   "metadata": {},
   "source": [
    "\n",
    "## 🧠 Ejercicio: Análisis de Sentimientos y Emociones en Opiniones de Usuarios\n",
    "\n",
    "### 📝 Objetivo\n",
    "Usar `pysentimiento` para analizar una serie de opiniones extraídas de redes sociales o reseñas, y comparar los resultados obtenidos con la intuición humana. Reflexionar sobre aciertos, errores y posibles fuentes de ambigüedad.\n",
    "\n",
    "### 📦 Materiales\n",
    "- Lista de 10 a 15 frases que simulen opiniones de usuarios (pueden ser reales o inventadas).\n",
    "- Un cuaderno (notebook) en Colab o Jupyter con `pysentimiento` instalado.\n",
    "\n",
    "### 🔧 Instrucciones\n",
    "\n",
    "1. **Preparación del Dataset**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b2b184",
   "metadata": {},
   "outputs": [],
   "source": [
    "opiniones = [\n",
    "       \"Me encantó la atención al cliente, volvería sin dudarlo.\",\n",
    "       \"Una pérdida de tiempo, el producto no sirve.\",\n",
    "       \"El hotel estaba bien, aunque el desayuno era mejorable.\",\n",
    "       \"No sé qué pensar, fue una experiencia rara.\",\n",
    "       \"¡Excelente servicio y muy rápido!\",\n",
    "       \"Demasiado caro para lo que ofrece.\",\n",
    "       \"No me gustó, pero entiendo que a otros sí.\",\n",
    "       \"La película fue una joya, me hizo llorar de emoción.\",\n",
    "       \"Malisimo, no lo recomiendo a nadie.\",\n",
    "       \"La app está bien diseñada, pero falla mucho.\"\n",
    "   ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3692703e",
   "metadata": {},
   "source": [
    "## 2. Predicción automática con PySentimiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a1fafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysentimiento import create_analyzer\n",
    "\n",
    "sentiment_analyzer = create_analyzer(task=\"sentiment\", lang=\"es\")\n",
    "emotion_analyzer = create_analyzer(task=\"emotion\", lang=\"es\")\n",
    "\n",
    "for frase in opiniones:\n",
    "    sentimiento = sentiment_analyzer.predict(frase)\n",
    "    emocion = emotion_analyzer.predict(frase)\n",
    "    print(f\"Frase: {frase}\")\n",
    "    print(f\"  ➤ Sentimiento: {sentimiento.output}, probabilidades: {sentimiento.probas}\")\n",
    "    print(f\"  ➤ Emoción: {emocion.output}, probabilidades: {emocion.probas}\")\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218a8495",
   "metadata": {},
   "source": [
    "### Tareas a realizar\n",
    "\n",
    "🧐 Clasificar cada frase como positiva, negativa o neutra antes de ejecutar el modelo. Luego comparalo con la predicción automática.\n",
    "\n",
    "❓ ¿Coincide tu intuición con la del modelo? ¿En qué casos no? ¿Por qué podría fallar el modelo?\n",
    "\n",
    "💡 Observar los casos donde el modelo predice neutral. ¿Te parece apropiado? ¿Qué tipo de lenguaje aparece allí?\n",
    "\n",
    "🔍 Revisar también las emociones detectadas. ¿Hay ambigüedad? ¿Captura bien la emoción dominante?\n",
    "\n",
    "🧪 Modificar algunas frases para ver cómo cambian las predicciones. Por ejemplo: \"El servicio fue increíblemente lento\" vs. \"El servicio fue lento, pero aceptable\".\n",
    "\n",
    "## Reflexión Final\n",
    "\n",
    "¿Qué fortalezas y limitaciones encontraste en el modelo?\n",
    "\n",
    "¿Qué tipos de sesgos podrían surgir si solo usamos este tipo de modelos para tomar decisiones?\n",
    "\n",
    "¿Cómo mejorarías este pipeline para un caso de uso real, como popr ej. para  monitorear opiniones sobre una marca?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ecaea2",
   "metadata": {},
   "source": [
    "   \n",
    "Para más información: [https://github.com/pysentimiento/pysentimiento](https://github.com/pysentimiento/pysentimiento)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
