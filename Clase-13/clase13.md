### Sugerencias de uso de la Notebook: 
- Sugerimos 'Abrir en Colab' y realizar una copia del cuaderno antes de usarlo.

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/seminario-algosups/seminario-algosups.github.io/blob/master/Clase-13/clase13.ipynb)

# Analisis de sentimiento

El an√°lisis de sentimiento es una tarea de procesamiento del lenguaje natural que forma parte del amplio campo de las tareas de clasificaci√≥n de textos (*text classification*).

La clasificaci√≥n de textos incluye adem√°s, entre otras tareas, la detecci√≥n de spam, la identificaci√≥n de idioma, la atribuci√≥n de autor√≠a y la detecci√≥n de t√≥picos (*topic detection*). M√°s recientemente, se incorpor√≥ el *toxicity detection*.

El an√°lisis de sentimiento, puntualmente, consiste en determinar autom√°ticamente si un texto resulta positivo, neutral o negativo.

Existen tres grandes enfoques:
- *Enfoques l√©xicos*: Calculan el sentimiento en funci√≥n de la presencia o no de ciertas palabras predefinidas de antemano, como, por ejemplo, subjetivemas, negaci√≥n, predicados de gusto, etc. Est√°n basados en reglas, lo que los hace menos flexibles.
- *Enfoques de aprendizaje autom√°tico*: Son mucho m√°s adecuados y flexibles, pero requieren de datos etiquetados.
- *Aprendizaje profundo con transformers preentrenados*: Son el estado del arte actual, pero requieren muchos recursos computacionales.


## Enfoques L√©xicos


```python

# Simulamos diccionarios l√©xicos simples
positivas = {"feliz", "bueno", "excelente", "maravilloso", "fant√°stico"}
negativas = {"malo", "horrible", "terrible", "feo", "asco"}

def analisis_lexico(texto):
    tokens = texto.lower().split()
    pos = sum(1 for t in tokens if t in positivas)
    neg = sum(1 for t in tokens if t in negativas)
    if pos > neg:
        return "POSITIVO"
    elif neg > pos:
        return "NEGATIVO"
    else:
        return "NEUTRO"

# Ejemplo
analisis_lexico("El d√≠a fue maravilloso pero la comida estuvo horrible")
```

## Enfoques de ML


```python
from datasets import load_dataset

# Cargar el dataset desde Hugging Face
dataset = load_dataset("mrm8488/tass-2019")
```


```python
dataset["train"][0]  # Ver el primer ejemplo del dataset
print(len(dataset["train"]))  # Ver el n√∫mero de ejemplos en el dataset
print(len(dataset["test"]))
```


```python
from pprint import pprint
pprint(dataset["train"][:10])
```


```python
import pandas as pd

#sampled = dataset["train"].train_test_split(test_size=0.5, seed=42)["test"]
#print(f"N√∫mero de ejemplos muestreados: {len(sampled)}")
#print(sampled[0])

# Convertir a DataFrame
df = pd.DataFrame(dataset["train"])
df = df[["sentence", "labels"]].dropna()

# Ver etiquetas √∫nicas
df["labels"].value_counts()
```


```python
from sklearn.feature_extraction.text import CountVectorizer

vectorizer = CountVectorizer()
X = vectorizer.fit_transform(df["sentence"])
y = df["labels"]

```


```python
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
clf = MultinomialNB()
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred))
```


```python
textos = [
    "Me encanta este producto", "Odio este lugar",
    "La pel√≠cula fue buena", "Es horrible y lento",
    "Excelente atenci√≥n", "Mal√≠simo todo", "La comida estuvo bien, la atenci√≥n podria mejorar bastante"
]
# Probar con el ds original!!
etiquetas = ["pos", "neg", "pos", "neg", "pos", "neg", "neg"]
# 0: neg, # 1: pos
df_testeos = pd.DataFrame({"text": textos, "label": etiquetas})

df_testeos["pred"] = clf.predict(vectorizer.transform(df_testeos["text"]))
```


```python
df_testeos
```

## Modelos basados en Transformers: 
1. Verificado
2. PySentimiento




```python
# Usando un modelo preentrenado de Hugging Face para an√°lisis de sentimientos
from transformers import pipeline

pipe = pipeline("text-classification", model="VerificadoProfesional/SaBERT-Spanish-Sentiment-Analysis")

for texto in textos:
    resultado = pipe(texto)
    print(f"Texto: {texto} -> Etiqueta: {resultado[0]['label']}, Score: {resultado[0]['score']:.4f}")
```

## PySentimiento: An√°lisis de Opini√≥n y NLP Social Multiling√ºe

`pysentimiento` es una biblioteca de Python que ofrece modelos preentrenados para tareas de procesamiento de lenguaje natural centradas en redes sociales. Es compatible con varios idiomas (espa√±ol, ingl√©s, portugu√©s, italiano) y permite realizar an√°lisis de sentimiento, detecci√≥n de emociones, discurso de odio, iron√≠a, an√°lisis de entidades nombradas (NER), y etiquetas gramaticales (POS).

A continuaci√≥n, se muestran ejemplos de uso con texto en espa√±ol.



```python

# Instalar pysentimiento (si no est√° instalado)
!pip install pysentimiento

```

## Flujo: del texto a la predicci√≥n

Para entender c√≥mo funciona internamente la herramienta, aqu√≠ se describe el pipeline t√≠pico que ocurre al llamar `analyzer.predict(text)`:

### 1. Preprocesamiento
El texto crudo se pasa primero por el preprocesador de tweets (a menos que est√© deshabilitado). Este paso limpia el texto aplicando reglas como la normalizaci√≥n de menciones y URLs, la reducci√≥n de repeticiones de caracteres, la conversi√≥n de emojis a texto, etc. El resultado es una versi√≥n normalizada del texto de entrada.

### 2. Tokenizaci√≥n
El tokenizador del analizador (una subclase de `AutoTokenizer` de Hugging Face) convierte el texto preprocesado en una secuencia de tokens/IDs que el modelo Transformer puede interpretar. Esto incluye dividir el texto en subpalabras y agregar tokens especiales (como `[CLS]` y `[SEP]` para BERT, o solo tokens de inicio/fin en el caso de RoBERTa). Tambi√©n se realiza padding o truncamiento seg√∫n la longitud m√°xima permitida.

### 3. Inferencia del Modelo
Los IDs de tokens se env√≠an al modelo Transformer (que internamente es un modelo de PyTorch). Dependiendo de la tarea:

- **Tareas de clasificaci√≥n:** El modelo produce un conjunto de logits (puntuaciones no normalizadas) para cada clase. Por ejemplo, el modelo de sentimiento devuelve tres logits (uno por cada clase: POS, NEG, NEU).
- **Tareas multi-etiqueta:** El modelo devuelve un logit por cada etiqueta posible (por ejemplo, tres logits para las etiquetas de discurso de odio: `hateful`, `targeted`, `aggressive`).
- **Tareas de etiquetado secuencial (NER/POS):** Se devuelve un logit por token por cada posible etiqueta.

### 4. Post-procesamiento de la Predicci√≥n
Los logits producidos por el modelo se convierten en probabilidades:

- Para clasificaci√≥n de una sola etiqueta, se aplica **softmax**, y se selecciona la etiqueta con mayor probabilidad como `output`.
- Para clasificaci√≥n multi-etiqueta (como discurso de odio), se aplica **sigmoid** a cada logit, y se seleccionan las etiquetas cuya probabilidad supera un umbral (por defecto, 0.5).


Luego, las etiquetas seleccionadas se ensamblan en un objeto 'resultado'.

### 5. Formato de Salida
El resultado se devuelve como un objeto `AnalyzerOutput` (o una lista si se procesan m√∫ltiples textos). Este objeto contiene:

- `output`: la etiqueta predicha (para tareas de una sola etiqueta) o una lista de etiquetas (para tareas multi-etiqueta). En tareas secuenciales como NER o POS, puede ser una lista de anotaciones por token.
- `probas`: un diccionario que asigna a cada etiqueta su probabilidad estimada.  
  Por ejemplo:
  ```python
  {'POS': 0.998, 'NEG': 0.002, 'NEU': 0.000}
  ```
  para una oraci√≥n claramente positiva, o:
  ```python
  {'hateful': 0.987, 'targeted': 0.978, 'aggressive': 0.969}
  ```
  ppara un texto con discurso de odio.

## Veamos algunos Ejemplos de funcionalidades

Tras la instalaci√≥n, el uso de la biblioteca es muy sencillo. 

Se crea un analizador para la tarea y el idioma de inter√©s y, a continuaci√≥n, se llama a la funcion 'predict' con nuevos textos. 

En este caso definimos como tarea el an√°lisis de sentimiento y el idioma que queremos usar como espa√±ol



```python

from pysentimiento import create_analyzer

# Analizador de sentimiento en espa√±ol
sentiment_analyzer = create_analyzer(task="sentiment", lang="es")

```


```python

texto_positivo = "Qu√© gran jugador es Messi"
texto_negativo = "Esto es p√©simo"
texto_neutro = "El evento ser√° a las 5 PM"

print("Positivo:", sentiment_analyzer.predict(texto_positivo))
print("Negativo:", sentiment_analyzer.predict(texto_negativo))
print("Neutro:", sentiment_analyzer.predict(texto_neutro))

```

## Emotion Analysis

`pysentimiento` provee an√°lisis de emociones a trav√©s de modelos pre-entrenados con los datasets de [EmoEvent](https://github.com/fmplaza/EmoEvent-multilingual-corpus/)


```python

emotion_analyzer = create_analyzer(task="emotion", lang="es")

print("Emoci√≥n:", emotion_analyzer.predict("Estoy muy feliz con el resultado"))

```

## Hate Speech
Replicamos la operaci√≥n pero esta ver para an√°lissi de odio


```python

hate_analyzer = create_analyzer(task="hate_speech", lang="es")

texto_odio = "Vaya guarra barata y de poca monta es XXXX!"
print("Discurso de odio:", hate_analyzer.predict(texto_odio))

```


```python

irony_analyzer = create_analyzer(task="irony", lang="es")

texto_ironia = "S√≠ claro, como si el gobierno alguna vez resolviera algo..."
print("Iron√≠a:", irony_analyzer.predict(texto_ironia))

```

## Token Labeling tasks


`pysentimiento` cuenta con analizadores para POS tagging & NER gracias al dataset multilingual [LinCE](https://ritual.uh.edu/lince/)


```python

from pysentimiento.preprocessing import preprocess_tweet

texto_tweet = "@usuario deber√≠as ver esto http://bit.ly/ejemplo jajajajajaja"
print("Texto original:", texto_tweet)
print("Preprocesado:", preprocess_tweet(texto_tweet))

```


```python

ner_analyzer = create_analyzer(task="ner", lang="es")

print("Entidades nombradas:", ner_analyzer.predict("Lionel Messi juega en el Inter de Miami"))

```


```python

pos_analyzer = create_analyzer(task="pos", lang="es")

print("POS tagging:", pos_analyzer.predict("Messi corre r√°pidamente con el bal√≥n"))

```


## üß† Ejercicio: An√°lisis de Sentimientos y Emociones en Opiniones de Usuarios

### üìù Objetivo
Usar `pysentimiento` para analizar una serie de opiniones extra√≠das de redes sociales o rese√±as, y comparar los resultados obtenidos con la intuici√≥n humana. Reflexionar sobre aciertos, errores y posibles fuentes de ambig√ºedad.

### üì¶ Materiales
- Lista de 10 a 15 frases que simulen opiniones de usuarios (pueden ser reales o inventadas).
- Un cuaderno (notebook) en Colab o Jupyter con `pysentimiento` instalado.

### üîß Instrucciones

1. **Preparaci√≥n del Dataset**





```python
opiniones = [
       "Me encant√≥ la atenci√≥n al cliente, volver√≠a sin dudarlo.",
       "Una p√©rdida de tiempo, el producto no sirve.",
       "El hotel estaba bien, aunque el desayuno era mejorable.",
       "No s√© qu√© pensar, fue una experiencia rara.",
       "¬°Excelente servicio y muy r√°pido!",
       "Demasiado caro para lo que ofrece.",
       "No me gust√≥, pero entiendo que a otros s√≠.",
       "La pel√≠cula fue una joya, me hizo llorar de emoci√≥n.",
       "Malisimo, no lo recomiendo a nadie.",
       "La app est√° bien dise√±ada, pero falla mucho."
   ]

```

## 2. Predicci√≥n autom√°tica con PySentimiento



```python
from pysentimiento import create_analyzer

sentiment_analyzer = create_analyzer(task="sentiment", lang="es")
emotion_analyzer = create_analyzer(task="emotion", lang="es")

for frase in opiniones:
    sentimiento = sentiment_analyzer.predict(frase)
    emocion = emotion_analyzer.predict(frase)
    print(f"Frase: {frase}")
    print(f"  ‚û§ Sentimiento: {sentimiento.output}, probabilidades: {sentimiento.probas}")
    print(f"  ‚û§ Emoci√≥n: {emocion.output}, probabilidades: {emocion.probas}")
    print("-" * 80)

```

### Tareas a realizar

üßê Clasificar cada frase como positiva, negativa o neutra antes de ejecutar el modelo. Luego comparalo con la predicci√≥n autom√°tica.

‚ùì ¬øCoincide tu intuici√≥n con la del modelo? ¬øEn qu√© casos no? ¬øPor qu√© podr√≠a fallar el modelo?

üí° Observar los casos donde el modelo predice neutral. ¬øTe parece apropiado? ¬øQu√© tipo de lenguaje aparece all√≠?

üîç Revisar tambi√©n las emociones detectadas. ¬øHay ambig√ºedad? ¬øCaptura bien la emoci√≥n dominante?

üß™ Modificar algunas frases para ver c√≥mo cambian las predicciones. Por ejemplo: "El servicio fue incre√≠blemente lento" vs. "El servicio fue lento, pero aceptable".

## Reflexi√≥n Final

¬øQu√© fortalezas y limitaciones encontraste en el modelo?

¬øQu√© tipos de sesgos podr√≠an surgir si solo usamos este tipo de modelos para tomar decisiones?

¬øC√≥mo mejorar√≠as este pipeline para un caso de uso real, como popr ej. para  monitorear opiniones sobre una marca?

   
Para m√°s informaci√≥n: [https://github.com/pysentimiento/pysentimiento](https://github.com/pysentimiento/pysentimiento)

