{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8c0c0a0",
   "metadata": {},
   "source": [
    "### Sugerencias de uso de la Notebook: \n",
    "- Sugerimos 'Abrir en Colab' y realizar una copia del cuaderno antes de usarlo.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/seminario-algosups/seminario-algosups.github.io/blob/master/Clase-14/Clase-14.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5930087e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotecas importadas correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Importaciones necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from pysentimiento.preprocessing import preprocess_tweet\n",
    "\n",
    "print(\"Bibliotecas importadas correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f22853",
   "metadata": {},
   "source": [
    "## Carga de datos\n",
    "Primero, dividimos nuestros datos en un conjunto de entrenamiento (para que el modelo aprenda) y un conjunto de prueba (para evaluarlo de forma objetiva)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52c000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Cargar el dataset desde Hugging Face\n",
    "dataset = load_dataset(\"mrm8488/tass-2019\")\n",
    "\n",
    "df = pd.DataFrame(dataset[\"train\"])\n",
    "# df_test = pd.DataFrame(dataset[\"test\"])\n",
    "\n",
    "df = df[[\"sentence\", \"labels\"]].dropna()\n",
    "#df_test = df_test[[\"sentence\", \"labels\"]].dropna()\n",
    "\n",
    "print(\"Dataset de ejemplo:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c88766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d031b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora limpiamos el df para quedarnos solo con las labels 0 (neg) y 1 (pos) \n",
    "clean_df_train = df[df['labels'].isin([0, 1])]\n",
    "clean_df_train[\"labels\"].unique()\n",
    "print(len(clean_df_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598ea6d0",
   "metadata": {},
   "source": [
    "## Normalizaci√≥n\n",
    "\n",
    "Como preprocesamiento vamos a aplicarle la funci√≥n de Pysentimiento \"preprocess_tweet\" a nuestro dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c75c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizamos los tweets unsando pysentimiento\n",
    "clean_df_train[\"sentence\"] = clean_df_train[\"sentence\"].apply(preprocess_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8b536f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ac√° hacemos un poco de trampa.\n",
    "# Duplicamos el dataset para ampliar la cantidad de datos y mejorar performance\n",
    "\n",
    "augmented_ds = pd.concat([clean_df_train, clean_df_train], ignore_index=True)\n",
    "print(len(augmented_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75facb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir el dataset en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    augmented_ds['sentence'], augmented_ds['labels'], test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda95928",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.iloc[0],\" --- \" ,y_test.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad1a652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos Stopwords\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop_words = list(set(stopwords.words('spanish')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a64a16",
   "metadata": {},
   "source": [
    "## Preprocesamiento y Vectorizaci√≥n\n",
    "\n",
    "Usaremos la t√©cnica TF-IDF (Term Frequency-Inverse Document Frequency):\n",
    "* TF (Frecuencia de T√©rmino): Mide qu√© tan frecuente es una palabra en un documento.\n",
    "* IDF (Frecuencia Inversa de Documento): Penaliza las palabras que son muy comunes en todos los documentos (como \"el\", \"la\", \"un\"), d√°ndole m√°s importancia a las palabras que son m√°s distintivas de un texto en particular.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc4861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Crear el vectorizador TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words=stop_words, max_features=1000) # Podemos a√±adir stop_words en espa√±ol si queremos\n",
    "\n",
    "# Aprender el vocabulario y transformar los datos de entrenamiento\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Usar el mismo vectorizador para transformar los datos de prueba\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "print(\"Dimensiones de la matriz TF-IDF de entrenamiento:\", X_train_tfidf.shape)\n",
    "print(\"Dimensiones de la matriz TF-IDF de prueba:\", X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953d5c71",
   "metadata": {},
   "source": [
    "## Entrenamiento y Evaluaci√≥n de Modelos\n",
    "Ahora viene la parte central. Entrenaremos cada uno de nuestros tres modelos con los mismos datos de entrenamiento y los evaluaremos con los mismos datos de prueba.\n",
    "\n",
    "### Modelo 1: Naive Bayes (Bayesiano Ingenuo)\n",
    "\n",
    "* Este modelo se basa en el Teorema de Bayes. \n",
    "* Calcula la probabilidad de que un texto pertenezca a una clase (ej. \"positivo\") dadas las palabras que contiene. Se le llama \"ingenuo\" (naive) porque asume que la presencia de una palabra es independiente de las dem√°s, lo cual no es cierto en el lenguaje.\n",
    "* Ideal para: Clasificaci√≥n de texto, es muy r√°pido y funciona bien con pocas muestras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf37684b",
   "metadata": {},
   "source": [
    "$$\n",
    "P(A \\mid B) = \\frac{P(B \\mid A) \\cdot P(A)}{P(B)}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Este teorema es fundamental en estad√≠stica bayesiana, y se interpreta como: la probabilidad de \n",
    "ùê¥\n",
    "dado \n",
    "ùêµ\n",
    "es igual a la probabilidad de \n",
    "ùêµ\n",
    "dado \n",
    "ùê¥\n",
    ", multiplicada por la probabilidad de \n",
    "ùê¥\n",
    ", dividida por la probabilidad de \n",
    "ùêµ\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f617d9",
   "metadata": {},
   "source": [
    "| Tarea                          | Por qu√© funciona bien                                                                                          |\n",
    "| ------------------------------ | -------------------------------------------------------------------------------------------------------------- |\n",
    "| Filtro de spam                 | Las palabras ‚Äúgratis‚Äù, ‚Äúpromoci√≥n‚Äù, ‚Äúurgente‚Äù tienen distribuciones muy distintas en spam vs. correo leg√≠timo. |\n",
    "| An√°lisis de sentimiento b√°sico | Las palabras ‚Äúexcelente‚Äù o ‚Äúhorrible‚Äù son fuertes pistas de polaridad.                                         |\n",
    "\n",
    "\n",
    "\n",
    "### Ventajas\n",
    "\n",
    "* Entrena y predice en milisegundos, incluso con miles de clases.\n",
    "* Requiere pocos datos para obtener un modelo √∫til.\n",
    "* Tolera muy bien vectores dispersos (bolsa-de-palabras, TF-IDF).\n",
    "\n",
    "\n",
    "### Limitaciones\n",
    "* La independencia entre palabras rara vez se cumple (p. ej. ‚Äúno me gust√≥‚Äù).\n",
    "* No captura interacciones ni pondera contextos complejos.\n",
    "* Suele dar menor exactitud que modelos discriminativos cuando hay mucho dato etiquetado.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452dc0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Entrenando Naive Bayes ---\")\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_nb = nb_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluaci√≥n\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "print(f\"Precisi√≥n (Accuracy) de Naive Bayes: {accuracy_nb:.2f}\")\n",
    "print(\"Reporte de Clasificaci√≥n:\")\n",
    "print(classification_report(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8611bda1",
   "metadata": {},
   "source": [
    "## Modelo 2: Regresi√≥n Log√≠stica\n",
    "\n",
    "* A pesar de su nombre, es un modelo de clasificaci√≥n. \n",
    "* Aprende una funci√≥n lineal que separa las clases. \n",
    "* Luego, usa una funci√≥n \"sigmoide\" para \"aplastar\" el resultado en una probabilidad (un valor entre 0 y 1). \n",
    "* * Si la probabilidad es > 0.5, se clasifica como una clase; si no, como la otra.\n",
    "\n",
    "* Ideal para: Problemas de clasificaci√≥n binaria donde se busca un modelo interpretable y eficiente. Es un excelente punto de partida (baseline).\n",
    "\n",
    "Es un modelo discriminativo lineal: aprende pesos ùë§ para cada caracter√≠stica y estima"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b240bd32",
   "metadata": {},
   "source": [
    "$$\n",
    "P(\\text{clase} = 1 \\mid \\mathbf{x}) = \\sigma(\\mathbf{w}^\\top \\mathbf{x})\n",
    "$$\n",
    "\n",
    "donde \n",
    "\n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33e351e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Regresi√≥n Log√≠stica ---\n",
    "print(\"\\n--- Entrenando Regresi√≥n Log√≠stica ---\")\n",
    "lr_model = LogisticRegression(C=2, solver='liblinear',random_state=42)\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_lr = lr_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluaci√≥n\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(f\"Precisi√≥n (Accuracy) de Regresi√≥n Log√≠stica: {accuracy_lr:.2f}\")\n",
    "print(\"Reporte de Clasificaci√≥n:\")\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75db9f2",
   "metadata": {},
   "source": [
    "## Modelo 3: M√°quina de Soporte Vectorial (SVM)\n",
    "* Intuici√≥n Te√≥rica: La SVM busca encontrar el hiperplano (una l√≠nea en 2D, un plano en 3D, etc.) que mejor separa las clases de datos. \n",
    "* No solo busca una l√≠nea que separe, sino la que tenga el margen m√°s amplio posible entre las clases. Esto lo hace muy robusto contra el ruido.\n",
    "\n",
    "* Ideal para: Espacios de alta dimensionalidad (como el texto vectorizado) y cuando la separaci√≥n clara entre clases es posible.\n",
    "\n",
    "\n",
    "### Ejemplos de casos\n",
    "\n",
    "* Clasificaci√≥n de temas de noticias con decenas de miles de palabras: un SVM lineal suele estar en el top-3 de exactitud.\n",
    "* Detecci√≥n de insultos en foros: con kernel RBF puede separar patrones de abuso m√°s sutiles que combinan palabras y n-gramas.\n",
    "\n",
    "#### Ventajas\n",
    "\n",
    "* Muy eficaz en espacios de alta dimensionalidad y datos dispersos (texto).\n",
    "\n",
    "* Buena gesti√≥n de clases desequilibradas (par√°metro class_weight).\n",
    "\n",
    "* El margen grande tiende a generalizar mejor en tests desconocidos.\n",
    "\n",
    "#### Limitaciones\n",
    "\n",
    "* Entrenamiento y predicci√≥n m√°s lentos que NB o RL en corpora enormes.\n",
    "\n",
    "* No produce probabilidades directas (se suele calibrar con Platt scaling).\n",
    "\n",
    "* Requiere ajustar hiperpar√°metros (C, kernel), lo que puede ser costoso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b8b8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n--- Entrenando SVM ---\")\n",
    "svm_model = SVC(kernel='rbf', random_state=42) \n",
    "svm_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_svm = svm_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluaci√≥n\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(f\"Precisi√≥n (Accuracy) de SVM: {accuracy_svm:.2f}\")\n",
    "print(\"Reporte de Clasificaci√≥n:\")\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3585e3",
   "metadata": {},
   "source": [
    "## Comparaci√≥n Final de Rendimiento\n",
    "Ahora que tenemos los resultados de cada modelo, vamos a ponerlos uno al lado del otro para una comparaci√≥n clara.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f889d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame con los resultados para una f√°cil comparaci√≥n\n",
    "results = {\n",
    "    'Modelo': ['Naive Bayes', 'Regresi√≥n Log√≠stica', 'SVM'],\n",
    "    'Accuracy': [accuracy_nb, accuracy_lr, accuracy_svm]\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\n--- Tabla Comparativa de Rendimiento ---\")\n",
    "print(results_df.sort_values(by='Accuracy', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b22ac31",
   "metadata": {},
   "source": [
    "## Primeras Conclusiones\n",
    "\n",
    "| Criterio                       | Naive Bayes                                               | Regresi√≥n Log√≠stica                                                                 | SVM                                                                                                      |\n",
    "| ------------------------------ | --------------------------------------------------------- | ----------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------- |\n",
    "| **Velocidad de entrenamiento** | ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ (instant√°neo)                                       | ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ                                                                               | ‚òÖ‚òÖ‚òÜ‚òÜ‚òÜ (datasets grandes)                                                                                 |\n",
    "| **Exactitud t√≠pica en texto**  | Buena como baseline                                       | Muy buena                                                                           | Excelente si el tuneo es correcto                                                                        |\n",
    "| **Probabilidades confiables**  | Aproximadas                                               | S√ç (calibradas)                                                                     | Necesita calibraci√≥n                                                                                     |\n",
    "| **Datos necesarios**           | Pocos                                                     | Moderados                                                                           | Muchos (especialmente con kernel)                                                                        |\n",
    "| **Interpretabilidad**          | Media (palabras con mayor prob.)                          | Alta (pesos directos)                                                               | Media-baja                                                                                               |\n",
    "| **Casos de uso recomendados**  | Baselines r√°pidos, streaming, spam, clasificaci√≥n inicial | Sentiment, intents, riesgo crediticio de textos, cuando se necesitan probabilidades | Categor√≠as finas, grandes corpus de noticias, detecci√≥n de fraude textual, problemas con margen estrecho |\n",
    "\n",
    "\n",
    "En nuestro peque√±o experimento, podemos observar el rendimiento de cada modelo. T√≠picamente, para tareas de texto:\n",
    "\n",
    "* Naive Bayes es un baseline incre√≠blemente r√°pido y s√≥lido.\n",
    "* Regresi√≥n Log√≠stica y SVM (con kernel lineal) suelen competir por el primer puesto e incluso ambos pueden ser m√°s precisos que Naive Bayes.\n",
    "\n",
    "### Puntos Clave a Recordar:\n",
    "* No hay un \"mejor\" modelo universal: El rendimiento depende del dataset, del preprocesamiento y de la tarea espec√≠fica.\n",
    "* La importancia del preprocesamiento: La calidad de la vectorizaci√≥n (TF-IDF en este caso) es tan importante como la elecci√≥n del modelo.\n",
    "* Fundamentales antes de saltar a arquitecturas m√°s complejas como los Transformers. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc12c715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(model, vectorizer, text):\n",
    "    \"\"\"\n",
    "    Funci√≥n para predecir el sentimiento de un texto dado un modelo y un vectorizador.\n",
    "    \"\"\"\n",
    "    text_processed = preprocess_tweet(text)\n",
    "    text_vectorized = vectorizer.transform([text_processed])\n",
    "    prediction = model.predict(text_vectorized)\n",
    "    return prediction[0]\n",
    "\n",
    "def make_prediction(text, model, vectorizer):\n",
    "    #norm_text = preprocess_tweet(text)\n",
    "    sentiment = predict_sentiment(model, vectorizer, text)\n",
    "    \n",
    "    sentiment_label = \"Positivo\" if sentiment == 1 else \"Negativo\"\n",
    "    return sentiment_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06acfef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.iloc[2],\" --- \" ,y_test.iloc[2])\n",
    "\n",
    "test_case = X_test.iloc[2]\n",
    "#make_prediction(\"La gente joven no encuentra sociego\", svm_model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b27aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e107c51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_prediction(test_case, svm_model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d537c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_prediction(\"Aaaa, pero que rica esta mierda #cocacola\", svm_model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27f8539",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e92dfcbc",
   "metadata": {},
   "source": [
    "## Ahora les toca a ustedes: \n",
    "* Definan un set de oraciones positivas y negativas para testear cada uno de los modelos.\n",
    "* Ejecutar la funci√≥n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5cd663",
   "metadata": {},
   "outputs": [],
   "source": [
    "positivas = [\"Agrega tu ejemplo\"]\n",
    "negativas = [\"Agrega tu ejemplo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485507a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = {\n",
    "    \"Naive Bayes\": nb_model,\n",
    "    \"Regresi√≥n Log√≠stica\": lr_model,\n",
    "    \"SVM\": svm_model\n",
    "}\n",
    "\n",
    "texts = positivas + negativas\n",
    "\n",
    "resultados = {\"Texto\": texts}\n",
    "for nombre, modelo in modelos.items():\n",
    "    resultados[nombre] = [make_prediction(text, modelo, vectorizer) for text in texts]\n",
    "\n",
    "comparacion_df = pd.DataFrame(resultados)\n",
    "comparacion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780a2f05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03132231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a86a115",
   "metadata": {},
   "outputs": [],
   "source": [
    "{% include additional_content.html %}\n",
    "{% include additional_content.html %}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
