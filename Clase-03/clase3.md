### Sugerencias de uso de la Notebook: 
-- Sugerimos 'Abrir en Colab' y realizar una copia del cuaderno antes de usarlo.

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/chafa618/curso_anotacion_puan/blob/main/Clase3/clase3.ipynb)

# Clase 3:

##  Aprendizaje supervisado vs. no supervisado

Cuando hablamos de AS y ANS, nos referimos a diferentes enfoques de aprendizaje autom谩tico. El aprendizaje autom谩tico estudia la construcci贸n de modelos capaces de aprender
ciertas estructuras a partir de la informaci贸n proporcionada por los datos. Es decir, el **aprendizaje autom谩tico se centra en encontrar patrones en los datos de tal forma que
podamos usar dichos patrones en puntos que no han sido observados previamente**



- **Aprendizaje supervisado**: El modelo aprende a partir de datos etiquetados, donde cada entrada tiene una salida asociada.
- **Aprendizaje no supervisado**: El modelo trabaja con datos no etiquetados, con el objetivo de descubrir patrones sin una salida espec铆fica.



<div style="text-align: center;">
    <img src="img/supvsunsup.png" alt="Clf vs Clustering">
</div>


###  Aprendizaje Supervisado:
- Un algoritmo usa un conjunto de datos de muestra para entrenarse, hacer predicciones y ajustarse de forma iterativa para minimizar los errores. Estos datos est谩n etiquetados con los valores de salida esperados, de forma tal que el modelo pueda dar una respuesta "acertada".
- Hay un conocimiento a priori que el modelo trata de aprender. Este tipo de algoritmo se centra en aprender la relaciones entre los datos de entrada y de salida (el dato y su etiqueta). 
- Es decuado para tareas de clasificaci贸n y regresi贸n, como la previsi贸n meteorol贸gica, los cambios de precios, el an谩lisis de opini贸n y la detecci贸n de spam.


###  Aprendizaje No supervisado:
- El algoritmo se entrena con un conjunto de datos no etiquetados, es decir, sin una salida esperada. El objetivo del Unsupervised Learning es encontrar patrones, estructuras y relaciones en los datos sin la necesidad de una orientaci贸n o gu铆a espec铆fica.
- No hay conocimiento a priori; el algoritmo recibe un conjunto de datos y busca patrones y similitudes por s铆 solo, sin que se le haya dicho de antemano qu茅 caracter铆sticas buscar e intenta agrupar los datos en funci贸n de similitudes y diferencias.
- Se utiliza ampliamente en el an谩lisis exploratorio de datos y tareas de agrupaci贸n, detecci贸n de anomal铆as y reducci贸n de dimensionalidad. 


|    | **Supervisado**                        | **No Supervisado**                    |
|--------------------|--------------------------------|--------------------------------|
| **Input**         | Dato etiquetado              | Dato crudo                    |
| **Output**        | Respuesta 'correcta' / etiqueta | Patrones                      |
| **Objetivo**      | Aprender relaciones entre los datos de entrada y de salida | Descubrir relaciones entre los datos sin etiquetar |
| **Tasks**         | Regresi贸n, clasificaci贸n     | Exploraci贸n, agrupaci贸n       |
| **Ejemplo**       | Detecci贸n de spam, previsi贸n meteorol贸gica | Detecci贸n de anomal铆as, segmentaci贸n de clientes |



###  Hagamos unos ejercicios:
1. Ten茅s un conjunto de datos con informaci贸n de diferentes casas, incluyendo la cantidad de habitaciones, metros cuadrados, ubicaci贸n y precio de venta. Quer茅s construir un modelo que, dado un conjunto de caracter铆sticas de una casa nueva, prediga su precio.

2. Un negocio de comercio electr贸nico quiere agrupar a sus clientes en diferentes segmentos seg煤n su comportamiento de compra, sin una etiqueta predefinida. Se analizan datos como el n煤mero de compras realizadas, el monto gastado y la frecuencia de compra.

3. Un banco quiere identificar transacciones sospechosas analizando patrones inusuales en el comportamiento de los clientes. No tiene ejemplos previos de fraude etiquetados, pero quiere detectar anomal铆as basadas en las transacciones habituales de cada cliente.

4. Un sistema de correo electr贸nico tiene un conjunto de datos con correos etiquetados como "spam" o "no spam". Quer茅s entrenar un modelo para clasificar autom谩ticamente nuevos correos en una de estas dos categor铆as.


##  Tareas de Clasificaci贸n y Regresi贸n

La **clasificaci贸n** es un m茅todo de machine learning supervisado en el que el modelo intenta prever la etiqueta correcta de unos datos de entrada dados. En este caso, el modelo se entrena con un dataset de entrenamiento y, luego, se eval煤a con los datos de prueba* con el objetivo de realizar predicciones sobre nuevos datos no vistos durante el entrenamiento. 
Hablamos de una tarea de **clasificaci贸n** cuando la variable objetivo es discreta. Por ejemplo, el analisis de sentimiento. 

Por otro lado, cuando la variable objetivo es continua estamos frente a un caso **regresi贸n**. Un ejemplo puede ser la previsi贸n del salario de una persona dados su nivel de estudios, su experiencia laboral, su ubicaci贸n geogr谩fica y su antig眉edad.

<div style="text-align: center;">
    <img src="img/supervised_clf.avif" alt="Clasificacion vs Regresion">
</div>



Si pensamos en el **analisis de sentimientos**, el objetivo central consiste en predecir a qu茅 **clase** pertenece un texto dado, que no hemos visto durante la fase de entrenamiento. Siendo dichas clases "Positivo", "Negativo" y/o "Neutro". 

En cambio, si nos centramos en **predecir el precio del alquiler** de los dptos en CABA estamos hablando de un valor continuo en funci贸n de las variables de entrada. El objetivo principal de los problemas de regresi贸n es estimar una funci贸n de mapeo en funci贸n de las variables de entrada y salida.



###  Ejercicio

Identificar:
- Problema a resolver
- Tipo de output variables (continuo | categ贸rico)
- De que tipo de problema estamos hablando en cada caso?




<div style="text-align: center;">
    <img src="img/regvsclf.png" alt="Clasificacion vs Regresion">
</div>

### 锔 Pero, pero pero... 

Sea cual fuere la tarea a la que nos enfrentemos, necesitaremos datos

##  Datos Estructurados vs. No Estructurados en Machine Learning

En el 谩mbito del machine learning, es crucial entender la diferencia entre datos estructurados y no estructurados, ya que esto influye en c贸mo se procesan y utilizan para entrenar modelos.

###  Datos Estructurados
Los datos estructurados son aquellos que est谩n organizados en un formato predefinido, como tablas en bases de datos relacionales. Estos datos tienen un esquema fijo con filas y columnas, donde cada columna representa una caracter铆stica espec铆fica y cada fila una instancia de datos. Ejemplos comunes incluyen hojas de c谩lculo y bases de datos SQL.

*Ejemplo*: Un dataset de ventas con columnas como `Fecha`, `Producto`, `Cantidad`, y `Precio`.

###  Datos No Estructurados
Los datos no estructurados no tienen un formato predefinido y no se ajustan f谩cilmente a un modelo tabular. Estos datos pueden incluir texto, im谩genes, audio, video, y otros tipos de contenido multimedia. Debido a su naturaleza, requieren t茅cnicas especiales para ser procesados y analizados.

*Ejemplo*: Correos electr贸nicos, publicaciones en redes sociales, im谩genes y videos.

La anotaci贸n de datos permite que los datos no estructurados se conviertan en datos estructurados, facilitando su uso en modelos de machine learning y mejorando la precisi贸n y efectividad de estos modelos.


##  Anotaci贸n
- La anotaci贸n de contenidos constituye un paso esencial para convertir datos crudos en recursos utilizables o que un algoritmo puede consumir. 
- Consiste en etiquetar y organizar los datos. 
- La tarea de anotaci贸n puede ser realizada manualmente por anotadores humanos o autom谩ticamente mediante t茅cnicas algor铆tmicas (con resultados m谩s o menos convincentes). Aunque, a menudo es necesaria la supervisi贸n humana para comprobar y corregir una anotaci贸n de datos con el fin de garantizar su fiabilidad.
- Este proceso requiere tanto de precisi贸n como de una comprension profunda del contexto de los datos, ya que la calidad de las anotaciones determina en gran medida la capacidadd de los algoritmos de generalizar a partir de los datos. 
- Un **dataset** es, justamente, un conjunto de datos (que puede o no estar etiquetado) recopilado con un fin espec铆fico.
- Las anotaciones de datos se usan tanto para crear datasets de entrenamiento, validaci贸n y de prueba. 
- Estos conjuntos de datos se utilizan para medir el rendimiento del modelo (validaci贸n y prueba)

### 锔 Anotaci贸n de Im谩genes

<div style="text-align: center;">
    <img src="img/labelimgs.png" alt="Anotaci贸n de Im谩genes">
</div>


### 锔 Anotaci贸n de Textos

<div style="text-align: center;">
    <img src="img/typestextannot.webp" alt="Clasificacion vs Regresion">
</div>

### 
- Anotaci贸n de entidades y dependencias
<div style="text-align: center;">
    <img src="img/stanfordann.png" alt="Stanford Annotations">
</div>


- Anotaci贸n Connlu
<div style="text-align: center;">
    <img src="img/conllann.ppm" alt="Connl">
</div>




##  M茅tricas para evaluar modelos de clasificaci贸n

- **Accuracy** (certeza): (Predicciones correctas / Total de predicciones).
- **Precisi贸n**: (Verdaderos Positivos / (Verdaderos Positivos + Falsos Positivos)).
- **Recall** (cobertura): (Verdaderos Positivos / (Verdaderos Positivos + Falsos Negativos)).


<div style="text-align: center;">
    <img src="img/apr.webp" alt="Precision, Recall, Accuracy">
</div>

### Recursos:
- [Documentaci贸n SkLearn](https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html)

##  Precisi贸n vs. Cobertura en Aprendizaje Autom谩tico
Cuando evaluamos un modelo de clasificaci贸n, es importante entender dos m茅tricas clave: precisi贸n (*precision*) y cobertura (*recall*). 
Ambas nos ayudan a medir qu茅 tan bien est谩 funcionando nuestro modelo, pero desde perspectivas diferentes.

####  Precisi贸n (Precision)
La precisi贸n se refiere al porcentaje de predicciones positivas que realmente son correctas. En otras palabras, mide cu谩ntos de los resultados identificados como positivos por el modelo son realmente relevantes.

 *Ejemplo*: Si un detector de spam identifica 100 correos como spam, pero solo 80 realmente lo son, la precisi贸n ser铆a del 80%.

###  Cobertura (Recall)
  La cobertura mide el porcentaje de los casos realmente positivos que el modelo detect贸 correctamente. Es decir, nos dice qu茅 tan bien el modelo encuentra todos los casos relevantes dentro del total existente.

 *Ejemplo*: Si en tu bandeja de entrada hay 120 correos de spam y el modelo detect贸 solo 80, la cobertura ser铆a del 80/120 = 66.6%.

###  Diferencia clave entre precisi贸n y cobertura
- Un modelo con **alta precisi贸n pero baja cobertura** es muy estricto: solo etiqueta como positivos los casos en los que est谩 muy seguro, pero puede dejar muchos sin detectar.
- Un modelo con **alta cobertura pero baja precisi贸n** etiqueta muchos casos como positivos, incluyendo algunos que no lo son (*falsos positivos*).
- El *equilibrio entre precisi贸n y cobertura* depende de la aplicaci贸n. En un detector de fraudes, preferimos alta precisi贸n (evitar falsos positivos), pero en un diagn贸stico m茅dico, priorizamos alta cobertura (detectar la mayor cantidad de casos).

###  F1-score: Equilibrando Precisi贸n y Cobertura
En la mayor铆a de los problemas de clasificaci贸n, podemos dar mayor prioridad a precisi贸n (precision) o a cobertura (recall), dependiendo del contexto. 

Sin embargo, en muchos casos necesitamos una m茅trica que combine ambas y nos d茅 una visi贸n equilibrada del rendimiento del modelo.

Esa m茅trica es el F1-score, que es la media arm贸nica entre precisi贸n y cobertura.

####  驴Por qu茅 usar F1-score?
Si s贸lo usamos precisi贸n, podr铆amos obtener un modelo que solo predice lo que est谩 muy seguro, dejando fuera muchos casos positivos reales.
Si, en cambio, nos concentramos solo en la recall o cobertura, podr铆amos tener un modelo que clasifica demasiados ejemplos como positivos, generando muchos falsos positivos.

El F1-score nos permite encontrar un balance entre ambas m茅tricas.

####  C谩lculo del F1-score
Se define con la siguiente f贸rmula:

<div style="text-align: center;background-color: white;">
    <img src="img/f1.webp" alt="Precision, Recall, Accuracy">
</div>
 
Esta es la media arm贸nica entre precisi贸n y cobertura.

 **Para tener en cuenta: El F1-score solo ser谩 alto si ambas m茅tricas son altas. Si una es muy baja, el F1-score tambi茅n ser谩 bajo.**



Por suerte para nosotros, o no, este tipo de m茅tricas ya est谩n implementadas y dicha implementacion no ser谩 vista en este curso. Por esto mismo, utilizaremos algunas de las herramientas provistas por librer铆as existentens. 


```python
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

resultado_esperado = ["SPAM", "NO_SPAM", "SPAM", "SPAM", "NO_SPAM", "SPAM"]
resultado_obtenido = ["SPAM", "NO_SPAM", "SPAM", "NO_SPAM", "NO_SPAM", "SPAM"]

y_true = [1, 0, 1, 1, 0, 1] 
y_pred = [1, 0, 1, 0, 0, 1]

print("Accuracy:", accuracy_score(y_true, y_pred))
print("Precisi贸n:", precision_score(y_true, y_pred))
print("Cobertura:", recall_score(y_true, y_pred))
print("F1-score: ", f1_score(y_true, y_pred))
```
