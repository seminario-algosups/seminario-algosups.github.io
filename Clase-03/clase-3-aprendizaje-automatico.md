### Sugerencias de uso de la Notebook: 
- Sugerimos 'Abrir en Colab' y realizar una copia del cuaderno antes de usarlo.
- Para acceder a la version .md --> [ac√°](https://colab.research.google.com/github/seminario-algosups/seminario-algosups.github.io/blob/master/Clase-03/clase-3-aprendizaje-automatico.md)

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/seminario-algosups/seminario-algosups.github.io/blob/master/Clase-03/clase-3-aprendizaje-automatico.ipynb)

# Clase 3:

## üìå Aprendizaje supervisado vs. no supervisado

Cuando hablamos de AS y ANS, nos referimos a diferentes enfoques de aprendizaje autom√°tico. El aprendizaje autom√°tico estudia la construcci√≥n de modelos capaces de aprender
ciertas estructuras a partir de la informaci√≥n proporcionada por los datos. Es decir, el **aprendizaje autom√°tico se centra en encontrar patrones en los datos de tal forma que
podamos usar dichos patrones en puntos que no han sido observados previamente**



- **Aprendizaje supervisado**: El modelo aprende a partir de datos etiquetados, donde cada entrada tiene una salida asociada.
- **Aprendizaje no supervisado**: El modelo trabaja con datos no etiquetados, con el objetivo de descubrir patrones sin una salida espec√≠fica.



<div style="text-align: center;">
    <img src="img/supvsunsup.png" alt="Clf vs Clustering">
</div>


### üìç Aprendizaje Supervisado:
- Un algoritmo usa un conjunto de datos de muestra para entrenarse, hacer predicciones y ajustarse de forma iterativa para minimizar los errores. Estos datos est√°n etiquetados con los valores de salida esperados, de forma tal que el modelo pueda dar una respuesta "acertada".
- Hay un conocimiento a priori que el modelo trata de aprender. Este tipo de algoritmo se centra en aprender la relaciones entre los datos de entrada y de salida (el dato y su etiqueta). 
- Es decuado para tareas de clasificaci√≥n y regresi√≥n, como la previsi√≥n meteorol√≥gica, los cambios de precios, el an√°lisis de opini√≥n y la detecci√≥n de spam.


### üìç Aprendizaje No supervisado:
- El algoritmo se entrena con un conjunto de datos no etiquetados, es decir, sin una salida esperada. El objetivo del Unsupervised Learning es encontrar patrones, estructuras y relaciones en los datos sin la necesidad de una orientaci√≥n o gu√≠a espec√≠fica.
- No hay conocimiento a priori; el algoritmo recibe un conjunto de datos y busca patrones y similitudes por s√≠ solo, sin que se le haya dicho de antemano qu√© caracter√≠sticas buscar e intenta agrupar los datos en funci√≥n de similitudes y diferencias.
- Se utiliza ampliamente en el an√°lisis exploratorio de datos y tareas de agrupaci√≥n, detecci√≥n de anomal√≠as y reducci√≥n de dimensionalidad. 


|    | **Supervisado**                        | **No Supervisado**                    |
|--------------------|--------------------------------|--------------------------------|
| **Input**         | Dato etiquetado              | Dato crudo                    |
| **Output**        | Respuesta 'correcta' / etiqueta | Patrones                      |
| **Objetivo**      | Aprender relaciones entre los datos de entrada y de salida | Descubrir relaciones entre los datos sin etiquetar |
| **Tasks**         | Regresi√≥n, clasificaci√≥n     | Exploraci√≥n, agrupaci√≥n       |
| **Ejemplo**       | Detecci√≥n de spam, previsi√≥n meteorol√≥gica | Detecci√≥n de anomal√≠as, segmentaci√≥n de clientes |



### üìù Hagamos unos ejercicios:
1. Ten√©s un conjunto de datos con informaci√≥n de diferentes casas, incluyendo la cantidad de habitaciones, metros cuadrados, ubicaci√≥n y precio de venta. Quer√©s construir un modelo que, dado un conjunto de caracter√≠sticas de una casa nueva, prediga su precio.

2. Un negocio de comercio electr√≥nico quiere agrupar a sus clientes en diferentes segmentos seg√∫n su comportamiento de compra, sin una etiqueta predefinida. Se analizan datos como el n√∫mero de compras realizadas, el monto gastado y la frecuencia de compra.

3. Un banco quiere identificar transacciones sospechosas analizando patrones inusuales en el comportamiento de los clientes. No tiene ejemplos previos de fraude etiquetados, pero quiere detectar anomal√≠as basadas en las transacciones habituales de cada cliente.

4. Un sistema de correo electr√≥nico tiene un conjunto de datos con correos etiquetados como "spam" o "no spam". Quer√©s entrenar un modelo para clasificar autom√°ticamente nuevos correos en una de estas dos categor√≠as.


## üìå Tareas de Clasificaci√≥n y Regresi√≥n

La **clasificaci√≥n** es un m√©todo de machine learning supervisado en el que el modelo intenta prever la etiqueta correcta de unos datos de entrada dados. En este caso, el modelo se entrena con un **dataset de entrenamiento** y, luego, se eval√∫a con los **datos de prueba* con el objetivo de realizar predicciones sobre **nuevos datos no vistos durante el entrenamiento**. 

Hablamos de una tarea de **clasificaci√≥n** cuando la variable objetivo es discreta. Por ejemplo, el analisis de sentimiento. 

Por otro lado, cuando la variable objetivo es continua estamos frente a un caso **regresi√≥n**. Un ejemplo puede ser la previsi√≥n del salario de una persona dados su nivel de estudios, su experiencia laboral, su ubicaci√≥n geogr√°fica y su antig√ºedad.

<div style="text-align: center;">
    <img src="img/supervised_clf.avif" alt="Clasificacion vs Regresion">
</div>



Si pensamos en el **analisis de sentimientos**, el objetivo central consiste en predecir a qu√© **clase** pertenece un texto dado, que no hemos visto durante la fase de entrenamiento. Siendo dichas clases "Positivo", "Negativo" y/o "Neutro". 

En cambio, si nos centramos en **predecir el precio del alquiler** de los dptos en CABA estamos hablando de un valor continuo en funci√≥n de las variables de entrada. El objetivo principal de los problemas de regresi√≥n es estimar una funci√≥n de mapeo en funci√≥n de las variables de entrada y salida.



### üîπ Ejercicio

Identificar:
- Problema a resolver
- Tipo de output variables (continuo | categ√≥rico)
- De que tipo de problema estamos hablando en cada caso?




<div style="text-align: center;">
    <img src="img/regvsclf.png" alt="Clasificacion vs Regresion">
</div>

### ‚ö†Ô∏è Pero, pero pero... 

Sea cual fuere la tarea a la que nos enfrentemos, necesitaremos datos

## üìå Datos Estructurados vs. No Estructurados en Machine Learning

En el √°mbito del machine learning, es crucial entender la diferencia entre datos estructurados y no estructurados, ya que esto influye en c√≥mo se procesan y utilizan para entrenar modelos.

### üîπ Datos Estructurados
Los datos estructurados son aquellos que est√°n organizados en un formato predefinido, como tablas en bases de datos relacionales. Estos datos tienen un esquema fijo con filas y columnas, donde cada columna representa una caracter√≠stica espec√≠fica y cada fila una instancia de datos. Ejemplos comunes incluyen hojas de c√°lculo y bases de datos SQL.

*Ejemplo*: Un dataset de ventas con columnas como `Fecha`, `Producto`, `Cantidad`, y `Precio`.

### üîπ Datos No Estructurados
Los datos no estructurados no tienen un formato predefinido y no se ajustan f√°cilmente a un modelo tabular. Estos datos pueden incluir texto, im√°genes, audio, video, y otros tipos de contenido multimedia. Debido a su naturaleza, requieren t√©cnicas especiales para ser procesados y analizados.

*Ejemplo*: Correos electr√≥nicos, publicaciones en redes sociales, im√°genes y videos.

La anotaci√≥n de datos permite que los datos no estructurados se conviertan en datos estructurados, facilitando su uso en modelos de machine learning y mejorando la precisi√≥n y efectividad de estos modelos.


## üìå Anotaci√≥n
- La anotaci√≥n de contenidos constituye un paso esencial para convertir datos crudos en recursos utilizables o que un algoritmo puede consumir. 
- Consiste en etiquetar y organizar los datos. 
- La tarea de anotaci√≥n puede ser realizada manualmente por anotadores humanos o autom√°ticamente mediante t√©cnicas algor√≠tmicas (con resultados m√°s o menos convincentes). Aunque, a menudo es necesaria la supervisi√≥n humana para comprobar y corregir una anotaci√≥n de datos con el fin de garantizar su fiabilidad.
- Este proceso requiere tanto de precisi√≥n como de una comprension profunda del contexto de los datos, ya que la calidad de las anotaciones determina en gran medida la capacidadd de los algoritmos de generalizar a partir de los datos. 
- Un **dataset** es, justamente, un conjunto de datos (que puede o no estar etiquetado) recopilado con un fin espec√≠fico.
- Las anotaciones de datos se usan tanto para crear datasets de entrenamiento, validaci√≥n y de prueba. 
- Estos conjuntos de datos se utilizan para medir el rendimiento del modelo (validaci√≥n y prueba)

### ‚úèÔ∏è Anotaci√≥n de Im√°genes

<div style="text-align: center;">
    <img src="img/labelimgs.png" alt="Anotaci√≥n de Im√°genes">
</div>


### ‚úèÔ∏è Anotaci√≥n de Textos

<div style="text-align: center;">
    <img src="img/typestextannot.webp" alt="Clasificacion vs Regresion">
</div>

### 
- Anotaci√≥n de entidades y dependencias
<div style="text-align: center;">
    <img src="img/stanfordann.png" alt="Stanford Annotations">
</div>


- Anotaci√≥n Connlu
<div style="text-align: center;">
    <img src="img/conllann.ppm" alt="Connl">
</div>




## üìå M√©tricas para evaluar modelos de clasificaci√≥n

- **Accuracy** (certeza): (Predicciones correctas / Total de predicciones).
- **Precisi√≥n**: (Verdaderos Positivos / (Verdaderos Positivos + Falsos Positivos)).
- **Recall** (cobertura): (Verdaderos Positivos / (Verdaderos Positivos + Falsos Negativos)).


<div style="text-align: center;">
    <img src="img/apr.webp" alt="Precision, Recall, Accuracy">
</div>

### Recursos:
- [Documentaci√≥n SkLearn](https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html)

## üìå Precisi√≥n vs. Cobertura en Aprendizaje Autom√°tico
Cuando evaluamos un modelo de clasificaci√≥n, es importante entender dos m√©tricas clave: precisi√≥n (*precision*) y cobertura (*recall*). 
Ambas nos ayudan a medir qu√© tan bien est√° funcionando nuestro modelo, pero desde perspectivas diferentes.

#### üîπ Precisi√≥n (Precision)
La precisi√≥n se refiere al porcentaje de predicciones positivas que realmente son correctas. En otras palabras, mide cu√°ntos de los resultados identificados como positivos por el modelo son realmente relevantes.

üìç *Ejemplo*: Si un detector de spam identifica 100 correos como spam, pero solo 80 realmente lo son, la precisi√≥n ser√≠a del 80%.

### üîπ Cobertura (Recall)
  La cobertura mide el porcentaje de los casos realmente positivos que el modelo detect√≥ correctamente. Es decir, nos dice qu√© tan bien el modelo encuentra todos los casos relevantes dentro del total existente.

üìç *Ejemplo*: Si en tu bandeja de entrada hay 120 correos de spam y el modelo detect√≥ solo 80, la cobertura ser√≠a del 80/120 = 66.6%.

### üìä Diferencia clave entre precisi√≥n y cobertura
- Un modelo con **alta precisi√≥n pero baja cobertura** es muy estricto: solo etiqueta como positivos los casos en los que est√° muy seguro, pero puede dejar muchos sin detectar.
- Un modelo con **alta cobertura pero baja precisi√≥n** etiqueta muchos casos como positivos, incluyendo algunos que no lo son (*falsos positivos*).
- El *equilibrio entre precisi√≥n y cobertura* depende de la aplicaci√≥n. En un detector de fraudes, preferimos alta precisi√≥n (evitar falsos positivos), pero en un diagn√≥stico m√©dico, priorizamos alta cobertura (detectar la mayor cantidad de casos).

### üìå F1-score: Equilibrando Precisi√≥n y Cobertura
En la mayor√≠a de los problemas de clasificaci√≥n, podemos dar mayor prioridad a precisi√≥n (precision) o a cobertura (recall), dependiendo del contexto. 

Sin embargo, en muchos casos necesitamos una m√©trica que combine ambas y nos d√© una visi√≥n equilibrada del rendimiento del modelo.

Esa m√©trica es el F1-score, que es la media arm√≥nica entre precisi√≥n y cobertura.

#### üîπ ¬øPor qu√© usar F1-score?
Si s√≥lo usamos precisi√≥n, podr√≠amos obtener un modelo que solo predice lo que est√° muy seguro, dejando fuera muchos casos positivos reales.
Si, en cambio, nos concentramos solo en la recall o cobertura, podr√≠amos tener un modelo que clasifica demasiados ejemplos como positivos, generando muchos falsos positivos.

El F1-score nos permite encontrar un balance entre ambas m√©tricas.

#### üìä C√°lculo del F1-score
Se define con la siguiente f√≥rmula:

<div style="text-align: center;background-color: white;">
    <img src="img/f1.webp" alt="Precision, Recall, Accuracy">
</div>
 
Esta es la media arm√≥nica entre precisi√≥n y cobertura.

üîπ **Para tener en cuenta: El F1-score solo ser√° alto si ambas m√©tricas son altas. Si una es muy baja, el F1-score tambi√©n ser√° bajo.**



Por suerte para nosotros, o no, este tipo de m√©tricas ya est√°n implementadas y dicha implementacion no ser√° vista en este curso. Por esto mismo, utilizaremos algunas de las herramientas provistas por librer√≠as existentens. 


```python
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score


resultado_esperado = ["SPAM", "NO_SPAM", "SPAM", "SPAM", "NO_SPAM", "SPAM"]
resultado_obtenido = ["SPAM", "NO_SPAM", "SPAM", "NO_SPAM", "NO_SPAM", "SPAM"]


print("\nComparaci√≥n de Resultados:")
print("-" * 50)
print("Email\tEsperado\tObtenido\tCorrecto?")
print("-" * 50)
for i in range(len(resultado_esperado)):
    correct = "‚úì" if resultado_esperado[i] == resultado_obtenido[i] else "‚úó"
    print(f"{i+1}\t{resultado_esperado[i]}\t{resultado_obtenido[i]}\t{correct}")


y_true = [1, 0, 1, 1, 0, 1]  # 1: SPAM, 0: NO_SPAM
y_pred = [1, 0, 1, 0, 0, 1]

print("\nM√©tricas de Evaluaci√≥n:")
print("-" * 50)
print(f"Accuracy: {accuracy_score(y_true, y_pred):.2f} - (Predicciones correctas / Total)")
print(f"Precisi√≥n: {precision_score(y_true, y_pred):.2f} - (Verdaderos SPAM / Total predichos como SPAM)")
print(f"Cobertura: {recall_score(y_true, y_pred):.2f} - (SPAM detectados / Total SPAM reales)")
print(f"F1-score: {f1_score(y_true, y_pred):.2f} - (Balance entre Precisi√≥n y Cobertura)")
```


```python
from funciones import train_sentiment_classifier

```


```python
model, report = train_sentiment_classifier()
```


```python
from pprint import pprint
pprint(report)
```

{% include copybutton.html %}
{% include additional_content.html %}
